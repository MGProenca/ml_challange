{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll explain the steps and thought process behind all my data processing, feature engineering, model creation, validation and optimizations.\n",
    "\n",
    "All the functions i wrote here were later organized in separate modules, this notebook is an example for explaining only \n",
    "\n",
    "The API will be documented separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martim/Traive/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My chosen task for this challange is to make an Agricultural commodity price forecasting model and implement it.\n",
    "\n",
    "For this i chose an avocado prices and sales dataset for the US that can be found here: https://www.kaggle.com/datasets/neuromusic/avocado-prices/data\n",
    "\n",
    "The dataset has weekly entries for Organic and Conventional avocados in lots of regions across the US.\n",
    "\n",
    "My specific task will be to do a 4 week ahead forecast for the average price of an avocado, for this I'll train one separate regressor model per region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are out of the box time series forecasting models, i choose to implement a regression model such as XGB for a few reasons:\n",
    "1) In my experience if well tuned it tends to perform better.\n",
    "2) Since this is an exercise that will not be worked upon in the real world and which the objective is purely a  technical evaluation, i believe a custom solution allows me more room to express skills in machine learning engineering than models like prophet.\n",
    "3) I got some free time this week. In a more time constrained environment where a couple percentage points of precision are not essential I would probably go for the easier route..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"neuromusic/avocado-prices\")\n",
    "\n",
    "    destination_folder = \"./data\"\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    # Move all files from source to destination\n",
    "    for filename in os.listdir(path):\n",
    "        source_file = os.path.join(path, filename)\n",
    "        destination_file = os.path.join(destination_folder, filename)\n",
    "        shutil.move(source_file, destination_file)\n",
    "\n",
    "    df = pd.read_csv('data/avocado.csv')\n",
    "    return df\n",
    "\n",
    "df = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0               0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1               1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2               2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3               3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4               4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "...           ...         ...           ...           ...      ...        ...   \n",
       "18244           7  2018-02-04          1.63      17074.83  2046.96    1529.20   \n",
       "18245           8  2018-01-28          1.71      13888.04  1191.70    3431.50   \n",
       "18246           9  2018-01-21          1.87      13766.76  1191.92    2452.79   \n",
       "18247          10  2018-01-14          1.93      16205.22  1527.63    2981.04   \n",
       "18248          11  2018-01-07          1.62      17489.58  2894.77    2356.13   \n",
       "\n",
       "         4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0       48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1       58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2      130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3       72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4       75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "...       ...         ...         ...         ...          ...           ...   \n",
       "18244    0.00    13498.67    13066.82      431.85          0.0       organic   \n",
       "18245    0.00     9264.84     8940.04      324.80          0.0       organic   \n",
       "18246  727.94     9394.11     9351.80       42.31          0.0       organic   \n",
       "18247  727.01    10969.54    10919.54       50.00          0.0       organic   \n",
       "18248  224.53    12014.15    11988.14       26.01          0.0       organic   \n",
       "\n",
       "       year            region  \n",
       "0      2015            Albany  \n",
       "1      2015            Albany  \n",
       "2      2015            Albany  \n",
       "3      2015            Albany  \n",
       "4      2015            Albany  \n",
       "...     ...               ...  \n",
       "18244  2018  WestTexNewMexico  \n",
       "18245  2018  WestTexNewMexico  \n",
       "18246  2018  WestTexNewMexico  \n",
       "18247  2018  WestTexNewMexico  \n",
       "18248  2018  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DF has a \"Unnamed: 0\" column with repeating indices regarding the weeks of the year for each region and each type of avocado. Since i'll be dealing with the dates later this column will be dropped. \n",
    "\n",
    "The date column needs to be a datetime, and the names are not standardized, so i'll write a preprocess function to fix all this details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date')\n",
    "    # df = df.set_index('Date')\n",
    "    df = df.drop(['Unnamed: 0', 'year'], axis=1)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    df.columns = df.columns.str[0].str.upper() + df.columns.str[1:]\n",
    "    return df\n",
    "\n",
    "df = preprocess_raw_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>27365.89</td>\n",
       "      <td>9307.34</td>\n",
       "      <td>3844.81</td>\n",
       "      <td>615.28</td>\n",
       "      <td>13598.46</td>\n",
       "      <td>13061.10</td>\n",
       "      <td>537.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9593</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.49</td>\n",
       "      <td>17723.17</td>\n",
       "      <td>1189.35</td>\n",
       "      <td>15628.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>905.55</td>\n",
       "      <td>905.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>161.68</td>\n",
       "      <td>206.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>HarrisburgScranton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.52</td>\n",
       "      <td>54956.80</td>\n",
       "      <td>3013.04</td>\n",
       "      <td>35456.88</td>\n",
       "      <td>1561.70</td>\n",
       "      <td>14925.18</td>\n",
       "      <td>11264.80</td>\n",
       "      <td>3660.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1505.12</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1129.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>374.35</td>\n",
       "      <td>186.67</td>\n",
       "      <td>187.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.36</td>\n",
       "      <td>908202.13</td>\n",
       "      <td>142681.06</td>\n",
       "      <td>463136.28</td>\n",
       "      <td>174975.75</td>\n",
       "      <td>127409.04</td>\n",
       "      <td>103579.41</td>\n",
       "      <td>22467.04</td>\n",
       "      <td>1362.59</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9010588.32</td>\n",
       "      <td>3999735.71</td>\n",
       "      <td>966589.50</td>\n",
       "      <td>30130.82</td>\n",
       "      <td>4014132.29</td>\n",
       "      <td>3398569.92</td>\n",
       "      <td>546409.74</td>\n",
       "      <td>69152.63</td>\n",
       "      <td>conventional</td>\n",
       "      <td>SouthCentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.42</td>\n",
       "      <td>163496.70</td>\n",
       "      <td>29253.30</td>\n",
       "      <td>5080.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129163.36</td>\n",
       "      <td>109052.26</td>\n",
       "      <td>20111.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>SouthCentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17673</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.70</td>\n",
       "      <td>190257.38</td>\n",
       "      <td>29644.09</td>\n",
       "      <td>70982.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89631.19</td>\n",
       "      <td>89424.11</td>\n",
       "      <td>207.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8814</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1774776.77</td>\n",
       "      <td>63905.98</td>\n",
       "      <td>908653.71</td>\n",
       "      <td>843.45</td>\n",
       "      <td>801373.63</td>\n",
       "      <td>774634.09</td>\n",
       "      <td>23833.93</td>\n",
       "      <td>2905.61</td>\n",
       "      <td>conventional</td>\n",
       "      <td>NewYork</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  TotalVolume        4046       4225       4770  \\\n",
       "11569 2015-01-04          1.75     27365.89     9307.34    3844.81     615.28   \n",
       "9593  2015-01-04          1.49     17723.17     1189.35   15628.27       0.00   \n",
       "10009 2015-01-04          1.68      2896.72      161.68     206.96       0.00   \n",
       "1819  2015-01-04          1.52     54956.80     3013.04   35456.88    1561.70   \n",
       "9333  2015-01-04          1.64      1505.12        1.27    1129.50       0.00   \n",
       "...          ...           ...          ...         ...        ...        ...   \n",
       "8574  2018-03-25          1.36    908202.13   142681.06  463136.28  174975.75   \n",
       "9018  2018-03-25          0.70   9010588.32  3999735.71  966589.50   30130.82   \n",
       "18141 2018-03-25          1.42    163496.70    29253.30    5080.04       0.00   \n",
       "17673 2018-03-25          1.70    190257.38    29644.09   70982.10       0.00   \n",
       "8814  2018-03-25          1.34   1774776.77    63905.98  908653.71     843.45   \n",
       "\n",
       "        TotalBags   SmallBags  LargeBags  XLargeBags          Type  \\\n",
       "11569    13598.46    13061.10     537.36        0.00       organic   \n",
       "9593       905.55      905.55       0.00        0.00       organic   \n",
       "10009     2528.08     2528.08       0.00        0.00       organic   \n",
       "1819     14925.18    11264.80    3660.38        0.00  conventional   \n",
       "9333       374.35      186.67     187.68        0.00       organic   \n",
       "...           ...         ...        ...         ...           ...   \n",
       "8574    127409.04   103579.41   22467.04     1362.59  conventional   \n",
       "9018   4014132.29  3398569.92  546409.74    69152.63  conventional   \n",
       "18141   129163.36   109052.26   20111.10        0.00       organic   \n",
       "17673    89631.19    89424.11     207.08        0.00       organic   \n",
       "8814    801373.63   774634.09   23833.93     2905.61  conventional   \n",
       "\n",
       "                   Region  \n",
       "11569           Southeast  \n",
       "9593              Chicago  \n",
       "10009  HarrisburgScranton  \n",
       "1819           Pittsburgh  \n",
       "9333                Boise  \n",
       "...                   ...  \n",
       "8574              Chicago  \n",
       "9018         SouthCentral  \n",
       "18141        SouthCentral  \n",
       "17673          California  \n",
       "8814              NewYork  \n",
       "\n",
       "[18249 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since i decided that i want to forecast the average avocado prices i need to aggregate the data that currently is separated by types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives a group and combines all the variables\n",
    "def aggregate_types(group):\n",
    "    total_volume = group['TotalVolume'].sum()\n",
    "    weighted_avg = (group['AveragePrice'] * group['TotalVolume']).sum() / total_volume\n",
    "    return pd.Series({\n",
    "        'Date': group['Date'].iloc[0],\n",
    "        'Region': group['Region'].iloc[0],\n",
    "        'AveragePrice_combined': weighted_avg, # The average price is wighted against the total volumes\n",
    "        'TotalVolume_combined': total_volume,\n",
    "        '4046_combined': group['4046'].sum(),\n",
    "        '4225_combined': group['4225'].sum(),\n",
    "        '4770_combined': group['4770'].sum(),\n",
    "        'TotalBags_combined': group['TotalBags'].sum(),\n",
    "        'SmallBags_combined': group['SmallBags'].sum(),\n",
    "        'LargeBags_combined': group['LargeBags'].sum(),\n",
    "        'XLargeBags_combined': group['XLargeBags'].sum(),\n",
    "    })\n",
    "\n",
    "def group_by_region(df):\n",
    "    combined_df = df.groupby(['Date', 'Region'])[df.columns].apply(aggregate_types).reset_index(drop=True)\n",
    "    return combined_df\n",
    "\n",
    "grouped_df = group_by_region(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the differences for an example date and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1373.95</td>\n",
       "      <td>57.42</td>\n",
       "      <td>153.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.9</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  AveragePrice  TotalVolume     4046      4225  4770  \\\n",
       "9177 2015-01-04          1.79      1373.95    57.42    153.88   0.0   \n",
       "51   2015-01-04          1.22     40873.28  2819.50  28287.42  49.9   \n",
       "\n",
       "      TotalBags  SmallBags  LargeBags  XLargeBags          Type  Region  \n",
       "9177    1162.65    1162.65       0.00         0.0       organic  Albany  \n",
       "51      9716.46    9186.93     529.53         0.0  conventional  Albany  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Date'] == '2015-01-04') & (df['Region'] == 'Albany')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>AveragePrice_combined</th>\n",
       "      <th>TotalVolume_combined</th>\n",
       "      <th>4046_combined</th>\n",
       "      <th>4225_combined</th>\n",
       "      <th>4770_combined</th>\n",
       "      <th>TotalBags_combined</th>\n",
       "      <th>SmallBags_combined</th>\n",
       "      <th>LargeBags_combined</th>\n",
       "      <th>XLargeBags_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.238537</td>\n",
       "      <td>42247.23</td>\n",
       "      <td>2876.92</td>\n",
       "      <td>28441.3</td>\n",
       "      <td>49.9</td>\n",
       "      <td>10879.11</td>\n",
       "      <td>10349.58</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Region  AveragePrice_combined  TotalVolume_combined  \\\n",
       "0 2015-01-04  Albany               1.238537              42247.23   \n",
       "\n",
       "   4046_combined  4225_combined  4770_combined  TotalBags_combined  \\\n",
       "0        2876.92        28441.3           49.9            10879.11   \n",
       "\n",
       "   SmallBags_combined  LargeBags_combined  XLargeBags_combined  \n",
       "0            10349.58              529.53                  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[(grouped_df['Date'] == '2015-01-04') & (grouped_df['Region'] == 'Albany')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i run the models in this aggregated data i loose the information about the dinamic between organic and conventional sales, so lets get this info back. For this I'll pivot the data and add the values as columns to my aggregated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_and_merge_numerical_columns(df, grouped_df, target_name):\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    # numerical_columns = numerical_columns.drop('AveragePrice')\n",
    "    # Pivots arround date and region to separate each type value a column\n",
    "    pivot_df = df.pivot(index=['Date','Region'], columns='Type', values=numerical_columns).reset_index()\n",
    "    # Uses _ to join names\n",
    "    pivot_df.columns = pivot_df.columns.map(lambda col: '_'.join(map(str, col)).strip('_'))\n",
    "    # Merges data back toghether with the grouped DF\n",
    "    merge_df = pd.merge(pivot_df, df[['Date', 'Type', 'Region']], on=['Date', 'Region'], how='left')\n",
    "    merge_df = pd.merge(merge_df, grouped_df, on=['Date', 'Region'], how='left')\n",
    "    # Since i pivoted the columns, now each row has the information of the AveragePrice \n",
    "    # for both organic and conventional, AND a type flag separating the entries. But since\n",
    "    # I need a target for the forecast, another merge is done to get the price for the row's type\n",
    "    merge_df = pd.merge(merge_df, df[['Region', 'Date', 'Type', target_name]], on=['Date', 'Region', 'Type'], how='left')\n",
    "    return merge_df\n",
    "\n",
    "target_name = 'AveragePrice'\n",
    "merge_df = pivot_and_merge_numerical_columns(df, grouped_df, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Type</th>\n",
       "      <th>AveragePrice_conventional</th>\n",
       "      <th>AveragePrice_organic</th>\n",
       "      <th>AveragePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>conventional</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>conventional</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>BaltimoreWashington</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date               Region          Type  AveragePrice_conventional  \\\n",
       "0 2015-01-04               Albany       organic                       1.22   \n",
       "1 2015-01-04               Albany  conventional                       1.22   \n",
       "2 2015-01-04              Atlanta  conventional                       1.00   \n",
       "3 2015-01-04              Atlanta       organic                       1.00   \n",
       "4 2015-01-04  BaltimoreWashington       organic                       1.08   \n",
       "\n",
       "   AveragePrice_organic  AveragePrice  \n",
       "0                  1.79          1.79  \n",
       "1                  1.79          1.22  \n",
       "2                  1.76          1.00  \n",
       "3                  1.76          1.76  \n",
       "4                  1.29          1.29  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df[['Date', 'Region', 'Type' ,'AveragePrice_conventional', 'AveragePrice_organic', 'AveragePrice']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now 2 entries for each date/region pair, one for organic an one for conventional, and those rows have information regarding the other. So i can use this to calculate lagged features in the future and since the grouping is done by date this does not leak future information for the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining everything in one function we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stage_1_data(configs):\n",
    "    df = load_raw_data()\n",
    "    df = preprocess_raw_data(df)\n",
    "    grouped_df = group_by_region(df)\n",
    "    merge_df = pivot_and_merge_numerical_columns(df, grouped_df, configs['target_name'])\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need to make features to feed my regression model.\n",
    "\n",
    "Since this is an exercise I'll be adding only lags and time related features. In a real world scenario more transformations can be applyied and tested to improve performance, such as seasonal decompositions, rolling statistics, cyclical features and etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a fuction to select one single region, since I'll be training a separate model for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_region(merge_df, region):\n",
    "    sel_df = merge_df[merge_df['Region'] == region].reset_index(drop=True)\n",
    "    return sel_df.drop(columns='Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create lagged columns for a single region, with an option for adding the region name to the created column (will be usefull later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags_single_column(sel_df, lags, lag_column, region_name=False):\n",
    "    '''Create lag features for a single region and lag column.\n",
    "\n",
    "    Parameters:\n",
    "    sel_df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    lags (list): A list of integers representing the lag periods to create.\n",
    "    lag_column (str): The name of the column for which to create lag features.\n",
    "    region_name (str or bool, optional): The name of the region to include in the lag feature names. \n",
    "                                         If False, the region name is not included. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the lag features.'''\n",
    "    # TODO Raise error if sel_df has multiple regions\n",
    "    lag_feats = pd.DataFrame(index=sel_df.index)\n",
    "    for lag in lags:\n",
    "        if region_name:\n",
    "            lag_feats[f'{region_name}_{lag_column}_lag_{lag}'] = sel_df.groupby('Type')[lag_column].shift(lag)\n",
    "        else:\n",
    "            lag_feats[f'{lag_column}_lag_{lag}'] = sel_df.groupby('Type')[lag_column].shift(lag)\n",
    "    return lag_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function that will serve to call the make_lags_single_column() function on desired columns, handling the logic for adding the col name as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_region_lags(region_filt_df, region_name, columns_to_lag, lags ,region_name_in_col = False):\n",
    "    lag_features = []\n",
    "    for col_name in columns_to_lag:\n",
    "        if region_name_in_col:\n",
    "            lag_features.append(make_lags_single_column(region_filt_df, lags, col_name, region_name))\n",
    "        else:\n",
    "            lag_features.append(make_lags_single_column(region_filt_df, lags, col_name))\n",
    "    return pd.concat(lag_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need a way to make the lagged features for a specific region from the merged dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we are at it, could it be that the market behaviour in region A influences the prices in region B?\n",
    "\n",
    "If we only calculate the lags from the target region, the models will loose this information. \n",
    "\n",
    "To account for this, I'll also calculate lags from a set of aggregated regions from the merged dataset and add them to my separate region models. Doing this i can feed the general market information to the models. \n",
    "\n",
    "Those \"Exogenous\" regions will be called aux_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To coordinate all those lagging and aux features operations I'll make a configs JSON that will specify what needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "        \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "        \"lags\":[4], # The lags to be calculated for all the columns of the selected target region\n",
    "        \"aux_regions\": ['TotalUS'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "        \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "                         '4046_combined', '4225_combined', '4770_combined', \n",
    "                         'TotalBags_combined', 'SmallBags_combined', \n",
    "                         'LargeBags_combined', 'XLargeBags_combined'],\n",
    "        \"aux_lags\": [4], # The lags of the aux features to be calculated\n",
    "    }\n",
    "\n",
    "# Here lets use only the fourth lag and only one aux_region simplyfy the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the objective is to make a 4 weeks ahead forecast, the minimum lag I can use is 4. Less than that, the model would not work in the real world. \n",
    "\n",
    "Eg: if im in week 5 and using the second lag as a feature, my fourth week forecast would need information from week 7, which is in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally i can make the function that will receive the complete merged dataframe, the specified configs and return the lagged columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_region_lags_df(merge_df, target_region, train_configs):\n",
    "    # Lags for the target region\n",
    "    region_filt_df = select_region(merge_df, target_region)\n",
    "    columns_to_lag = merge_df.loc[:, merge_df.columns != train_configs['target_name']].select_dtypes(\n",
    "        include=['number']).columns\n",
    "    target_region_lags_df = make_region_lags(region_filt_df, target_region, columns_to_lag, train_configs['lags'])\n",
    "\n",
    "    # Lags for Auxiliary regions\n",
    "    aux_regions_lags = []\n",
    "    for aux_region_name in train_configs['aux_regions']:\n",
    "        if aux_region_name == target_region:\n",
    "            continue\n",
    "        \n",
    "        aux_region_filt_df = select_region(merge_df, aux_region_name).reset_index()\n",
    "        aux_regions_lags.append(\n",
    "            make_region_lags(\n",
    "                aux_region_filt_df, \n",
    "                aux_region_name, \n",
    "                train_configs['aux_features'], \n",
    "                train_configs['aux_lags'],\n",
    "                region_name_in_col=True))\n",
    "    aux_regions_lags_df = pd.concat(aux_regions_lags, axis=1)\n",
    "\n",
    "    return pd.concat([target_region_lags_df, aux_regions_lags_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i can get my lags with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Albany'\n",
    "lags_df = make_target_region_lags_df(merge_df, region, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice_conventional_lag_4</th>\n",
       "      <th>AveragePrice_organic_lag_4</th>\n",
       "      <th>TotalVolume_conventional_lag_4</th>\n",
       "      <th>TotalVolume_organic_lag_4</th>\n",
       "      <th>4046_conventional_lag_4</th>\n",
       "      <th>4046_organic_lag_4</th>\n",
       "      <th>4225_conventional_lag_4</th>\n",
       "      <th>4225_organic_lag_4</th>\n",
       "      <th>4770_conventional_lag_4</th>\n",
       "      <th>4770_organic_lag_4</th>\n",
       "      <th>...</th>\n",
       "      <th>XLargeBags_combined_lag_4</th>\n",
       "      <th>TotalUS_AveragePrice_combined_lag_4</th>\n",
       "      <th>TotalUS_TotalVolume_combined_lag_4</th>\n",
       "      <th>TotalUS_4046_combined_lag_4</th>\n",
       "      <th>TotalUS_4225_combined_lag_4</th>\n",
       "      <th>TotalUS_4770_combined_lag_4</th>\n",
       "      <th>TotalUS_TotalBags_combined_lag_4</th>\n",
       "      <th>TotalUS_SmallBags_combined_lag_4</th>\n",
       "      <th>TotalUS_LargeBags_combined_lag_4</th>\n",
       "      <th>TotalUS_XLargeBags_combined_lag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.45</td>\n",
       "      <td>1.43</td>\n",
       "      <td>121804.36</td>\n",
       "      <td>3817.93</td>\n",
       "      <td>8183.48</td>\n",
       "      <td>59.18</td>\n",
       "      <td>95548.47</td>\n",
       "      <td>289.85</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>451.11</td>\n",
       "      <td>0.987467</td>\n",
       "      <td>44484806.56</td>\n",
       "      <td>15969142.96</td>\n",
       "      <td>11812643.14</td>\n",
       "      <td>654696.38</td>\n",
       "      <td>16048064.96</td>\n",
       "      <td>11613094.64</td>\n",
       "      <td>4200629.04</td>\n",
       "      <td>234341.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.00</td>\n",
       "      <td>1.100729</td>\n",
       "      <td>38524817.46</td>\n",
       "      <td>13509266.77</td>\n",
       "      <td>11171955.89</td>\n",
       "      <td>554875.19</td>\n",
       "      <td>13288489.86</td>\n",
       "      <td>9806369.66</td>\n",
       "      <td>3254341.43</td>\n",
       "      <td>227778.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.00</td>\n",
       "      <td>1.100729</td>\n",
       "      <td>38524817.46</td>\n",
       "      <td>13509266.77</td>\n",
       "      <td>11171955.89</td>\n",
       "      <td>554875.19</td>\n",
       "      <td>13288489.86</td>\n",
       "      <td>9806369.66</td>\n",
       "      <td>3254341.43</td>\n",
       "      <td>227778.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.56</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.00</td>\n",
       "      <td>1.077948</td>\n",
       "      <td>41481381.31</td>\n",
       "      <td>13952770.84</td>\n",
       "      <td>10755838.42</td>\n",
       "      <td>725393.48</td>\n",
       "      <td>16046348.64</td>\n",
       "      <td>11431999.60</td>\n",
       "      <td>4310556.28</td>\n",
       "      <td>303792.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.56</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.00</td>\n",
       "      <td>1.077948</td>\n",
       "      <td>41481381.31</td>\n",
       "      <td>13952770.84</td>\n",
       "      <td>10755838.42</td>\n",
       "      <td>725393.48</td>\n",
       "      <td>16046348.64</td>\n",
       "      <td>11431999.60</td>\n",
       "      <td>4310556.28</td>\n",
       "      <td>303792.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AveragePrice_conventional_lag_4  AveragePrice_organic_lag_4  \\\n",
       "0                                NaN                         NaN   \n",
       "1                                NaN                         NaN   \n",
       "2                                NaN                         NaN   \n",
       "3                                NaN                         NaN   \n",
       "4                                NaN                         NaN   \n",
       "..                               ...                         ...   \n",
       "333                             1.45                        1.43   \n",
       "334                             1.43                        1.43   \n",
       "335                             1.43                        1.43   \n",
       "336                             1.28                        1.56   \n",
       "337                             1.28                        1.56   \n",
       "\n",
       "     TotalVolume_conventional_lag_4  TotalVolume_organic_lag_4  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "..                              ...                        ...   \n",
       "333                       121804.36                    3817.93   \n",
       "334                        85630.24                    7566.17   \n",
       "335                        85630.24                    7566.17   \n",
       "336                       104278.89                    5356.63   \n",
       "337                       104278.89                    5356.63   \n",
       "\n",
       "     4046_conventional_lag_4  4046_organic_lag_4  4225_conventional_lag_4  \\\n",
       "0                        NaN                 NaN                      NaN   \n",
       "1                        NaN                 NaN                      NaN   \n",
       "2                        NaN                 NaN                      NaN   \n",
       "3                        NaN                 NaN                      NaN   \n",
       "4                        NaN                 NaN                      NaN   \n",
       "..                       ...                 ...                      ...   \n",
       "333                  8183.48               59.18                 95548.47   \n",
       "334                  5499.73             4314.30                 61661.76   \n",
       "335                  5499.73             4314.30                 61661.76   \n",
       "336                 10368.77              816.56                 59723.32   \n",
       "337                 10368.77              816.56                 59723.32   \n",
       "\n",
       "     4225_organic_lag_4  4770_conventional_lag_4  4770_organic_lag_4  ...  \\\n",
       "0                   NaN                      NaN                 NaN  ...   \n",
       "1                   NaN                      NaN                 NaN  ...   \n",
       "2                   NaN                      NaN                 NaN  ...   \n",
       "3                   NaN                      NaN                 NaN  ...   \n",
       "4                   NaN                      NaN                 NaN  ...   \n",
       "..                  ...                      ...                 ...  ...   \n",
       "333              289.85                     61.0                 0.0  ...   \n",
       "334              251.85                     75.0                 0.0  ...   \n",
       "335              251.85                     75.0                 0.0  ...   \n",
       "336              532.59                     48.0                 0.0  ...   \n",
       "337              532.59                     48.0                 0.0  ...   \n",
       "\n",
       "     XLargeBags_combined_lag_4  TotalUS_AveragePrice_combined_lag_4  \\\n",
       "0                          NaN                                  NaN   \n",
       "1                          NaN                                  NaN   \n",
       "2                          NaN                                  NaN   \n",
       "3                          NaN                                  NaN   \n",
       "4                          NaN                                  NaN   \n",
       "..                         ...                                  ...   \n",
       "333                     451.11                             0.987467   \n",
       "334                     380.00                             1.100729   \n",
       "335                     380.00                             1.100729   \n",
       "336                     310.00                             1.077948   \n",
       "337                     310.00                             1.077948   \n",
       "\n",
       "     TotalUS_TotalVolume_combined_lag_4  TotalUS_4046_combined_lag_4  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "..                                  ...                          ...   \n",
       "333                         44484806.56                  15969142.96   \n",
       "334                         38524817.46                  13509266.77   \n",
       "335                         38524817.46                  13509266.77   \n",
       "336                         41481381.31                  13952770.84   \n",
       "337                         41481381.31                  13952770.84   \n",
       "\n",
       "     TotalUS_4225_combined_lag_4  TotalUS_4770_combined_lag_4  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "..                           ...                          ...   \n",
       "333                  11812643.14                    654696.38   \n",
       "334                  11171955.89                    554875.19   \n",
       "335                  11171955.89                    554875.19   \n",
       "336                  10755838.42                    725393.48   \n",
       "337                  10755838.42                    725393.48   \n",
       "\n",
       "     TotalUS_TotalBags_combined_lag_4  TotalUS_SmallBags_combined_lag_4  \\\n",
       "0                                 NaN                               NaN   \n",
       "1                                 NaN                               NaN   \n",
       "2                                 NaN                               NaN   \n",
       "3                                 NaN                               NaN   \n",
       "4                                 NaN                               NaN   \n",
       "..                                ...                               ...   \n",
       "333                       16048064.96                       11613094.64   \n",
       "334                       13288489.86                        9806369.66   \n",
       "335                       13288489.86                        9806369.66   \n",
       "336                       16046348.64                       11431999.60   \n",
       "337                       16046348.64                       11431999.60   \n",
       "\n",
       "     TotalUS_LargeBags_combined_lag_4  TotalUS_XLargeBags_combined_lag_4  \n",
       "0                                 NaN                                NaN  \n",
       "1                                 NaN                                NaN  \n",
       "2                                 NaN                                NaN  \n",
       "3                                 NaN                                NaN  \n",
       "4                                 NaN                                NaN  \n",
       "..                                ...                                ...  \n",
       "333                        4200629.04                          234341.28  \n",
       "334                        3254341.43                          227778.77  \n",
       "335                        3254341.43                          227778.77  \n",
       "336                        4310556.28                          303792.76  \n",
       "337                        4310556.28                          303792.76  \n",
       "\n",
       "[338 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice_conventional_lag_4', 'AveragePrice_organic_lag_4',\n",
       "       'TotalVolume_conventional_lag_4', 'TotalVolume_organic_lag_4',\n",
       "       '4046_conventional_lag_4', '4046_organic_lag_4',\n",
       "       '4225_conventional_lag_4', '4225_organic_lag_4',\n",
       "       '4770_conventional_lag_4', '4770_organic_lag_4',\n",
       "       'TotalBags_conventional_lag_4', 'TotalBags_organic_lag_4',\n",
       "       'SmallBags_conventional_lag_4', 'SmallBags_organic_lag_4',\n",
       "       'LargeBags_conventional_lag_4', 'LargeBags_organic_lag_4',\n",
       "       'XLargeBags_conventional_lag_4', 'XLargeBags_organic_lag_4',\n",
       "       'AveragePrice_combined_lag_4', 'TotalVolume_combined_lag_4',\n",
       "       '4046_combined_lag_4', '4225_combined_lag_4', '4770_combined_lag_4',\n",
       "       'TotalBags_combined_lag_4', 'SmallBags_combined_lag_4',\n",
       "       'LargeBags_combined_lag_4', 'XLargeBags_combined_lag_4',\n",
       "       'TotalUS_AveragePrice_combined_lag_4',\n",
       "       'TotalUS_TotalVolume_combined_lag_4', 'TotalUS_4046_combined_lag_4',\n",
       "       'TotalUS_4225_combined_lag_4', 'TotalUS_4770_combined_lag_4',\n",
       "       'TotalUS_TotalBags_combined_lag_4', 'TotalUS_SmallBags_combined_lag_4',\n",
       "       'TotalUS_LargeBags_combined_lag_4',\n",
       "       'TotalUS_XLargeBags_combined_lag_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encodes and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add back date, type and target info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_filt_df = select_region(merge_df, region)\n",
    "feat_df = pd.concat([\n",
    "    region_filt_df[['Date', 'Type', configs['target_name']]], \n",
    "    lags_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression models need those, so lets add them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_features(sel_df):\n",
    "    time_feats = pd.DataFrame(index=sel_df.index)\n",
    "    dates = sel_df['Date']\n",
    "    time_feats['Year'] = dates.dt.year\n",
    "    time_feats['Month'] = dates.dt.month\n",
    "    time_feats['Day'] = dates.dt.day\n",
    "    time_feats['DayofWeek'] = dates.dt.dayofweek\n",
    "    time_feats[\"WeekofYear\"] = dates.dt.isocalendar().week\n",
    "    time_feats[\"Quarter\"] = dates.dt.quarter\n",
    "    return time_feats\n",
    "\n",
    "feat_df = pd.concat([feat_df, make_time_features(feat_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.get_dummies(feat_df, columns=['Type'], prefix='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are concatenating, with different regions, there is a chance some dates are present in one but not the other, so just dropping the nulls solves it. (In the real world more appropriate data quality checks can be implemented in a prior data engineering stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = feat_df.loc[~feat_df['Date'].isnull(), :]\n",
    "dates = feat_df['Date'] # also store the dates not to loose the info (usefull for plotting)\n",
    "feat_df = feat_df.drop(columns='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, now I'll make the model ready data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat_df[feat_df.columns.difference([configs['target_name']])]\n",
    "y = feat_df[configs['target_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4046_combined_lag_4</th>\n",
       "      <th>4046_conventional_lag_4</th>\n",
       "      <th>4046_organic_lag_4</th>\n",
       "      <th>4225_combined_lag_4</th>\n",
       "      <th>4225_conventional_lag_4</th>\n",
       "      <th>4225_organic_lag_4</th>\n",
       "      <th>4770_combined_lag_4</th>\n",
       "      <th>4770_conventional_lag_4</th>\n",
       "      <th>4770_organic_lag_4</th>\n",
       "      <th>AveragePrice_combined_lag_4</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalVolume_combined_lag_4</th>\n",
       "      <th>TotalVolume_conventional_lag_4</th>\n",
       "      <th>TotalVolume_organic_lag_4</th>\n",
       "      <th>Type_conventional</th>\n",
       "      <th>Type_organic</th>\n",
       "      <th>WeekofYear</th>\n",
       "      <th>XLargeBags_combined_lag_4</th>\n",
       "      <th>XLargeBags_conventional_lag_4</th>\n",
       "      <th>XLargeBags_organic_lag_4</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>8242.66</td>\n",
       "      <td>8183.48</td>\n",
       "      <td>59.18</td>\n",
       "      <td>95838.32</td>\n",
       "      <td>95548.47</td>\n",
       "      <td>289.85</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.449392</td>\n",
       "      <td>...</td>\n",
       "      <td>125622.29</td>\n",
       "      <td>121804.36</td>\n",
       "      <td>3817.93</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>451.11</td>\n",
       "      <td>451.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>9814.03</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61913.61</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>93196.41</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>380.00</td>\n",
       "      <td>380.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>9814.03</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61913.61</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>93196.41</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>380.00</td>\n",
       "      <td>380.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>11185.33</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>60255.91</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293680</td>\n",
       "      <td>...</td>\n",
       "      <td>109635.52</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>310.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>11185.33</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>60255.91</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293680</td>\n",
       "      <td>...</td>\n",
       "      <td>109635.52</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>310.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4046_combined_lag_4  4046_conventional_lag_4  4046_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333              8242.66                  8183.48               59.18   \n",
       "334              9814.03                  5499.73             4314.30   \n",
       "335              9814.03                  5499.73             4314.30   \n",
       "336             11185.33                 10368.77              816.56   \n",
       "337             11185.33                 10368.77              816.56   \n",
       "\n",
       "     4225_combined_lag_4  4225_conventional_lag_4  4225_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333             95838.32                 95548.47              289.85   \n",
       "334             61913.61                 61661.76              251.85   \n",
       "335             61913.61                 61661.76              251.85   \n",
       "336             60255.91                 59723.32              532.59   \n",
       "337             60255.91                 59723.32              532.59   \n",
       "\n",
       "     4770_combined_lag_4  4770_conventional_lag_4  4770_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333                 61.0                     61.0                 0.0   \n",
       "334                 75.0                     75.0                 0.0   \n",
       "335                 75.0                     75.0                 0.0   \n",
       "336                 48.0                     48.0                 0.0   \n",
       "337                 48.0                     48.0                 0.0   \n",
       "\n",
       "     AveragePrice_combined_lag_4  ...  TotalVolume_combined_lag_4  \\\n",
       "0                            NaN  ...                         NaN   \n",
       "1                            NaN  ...                         NaN   \n",
       "2                            NaN  ...                         NaN   \n",
       "3                            NaN  ...                         NaN   \n",
       "4                            NaN  ...                         NaN   \n",
       "..                           ...  ...                         ...   \n",
       "333                     1.449392  ...                   125622.29   \n",
       "334                     1.430000  ...                    93196.41   \n",
       "335                     1.430000  ...                    93196.41   \n",
       "336                     1.293680  ...                   109635.52   \n",
       "337                     1.293680  ...                   109635.52   \n",
       "\n",
       "     TotalVolume_conventional_lag_4  TotalVolume_organic_lag_4  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "..                              ...                        ...   \n",
       "333                       121804.36                    3817.93   \n",
       "334                        85630.24                    7566.17   \n",
       "335                        85630.24                    7566.17   \n",
       "336                       104278.89                    5356.63   \n",
       "337                       104278.89                    5356.63   \n",
       "\n",
       "     Type_conventional  Type_organic  WeekofYear  XLargeBags_combined_lag_4  \\\n",
       "0                False          True           1                        NaN   \n",
       "1                 True         False           1                        NaN   \n",
       "2                False          True           2                        NaN   \n",
       "3                 True         False           2                        NaN   \n",
       "4                 True         False           3                        NaN   \n",
       "..                 ...           ...         ...                        ...   \n",
       "333              False          True          10                     451.11   \n",
       "334              False          True          11                     380.00   \n",
       "335               True         False          11                     380.00   \n",
       "336               True         False          12                     310.00   \n",
       "337              False          True          12                     310.00   \n",
       "\n",
       "     XLargeBags_conventional_lag_4  XLargeBags_organic_lag_4  Year  \n",
       "0                              NaN                       NaN  2015  \n",
       "1                              NaN                       NaN  2015  \n",
       "2                              NaN                       NaN  2015  \n",
       "3                              NaN                       NaN  2015  \n",
       "4                              NaN                       NaN  2015  \n",
       "..                             ...                       ...   ...  \n",
       "333                         451.11                       0.0  2018  \n",
       "334                         380.00                       0.0  2018  \n",
       "335                         380.00                       0.0  2018  \n",
       "336                         310.00                       0.0  2018  \n",
       "337                         310.00                       0.0  2018  \n",
       "\n",
       "[338 rows x 44 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4046_combined_lag_4', '4046_conventional_lag_4', '4046_organic_lag_4',\n",
       "       '4225_combined_lag_4', '4225_conventional_lag_4', '4225_organic_lag_4',\n",
       "       '4770_combined_lag_4', '4770_conventional_lag_4', '4770_organic_lag_4',\n",
       "       'AveragePrice_combined_lag_4', 'AveragePrice_conventional_lag_4',\n",
       "       'AveragePrice_organic_lag_4', 'Day', 'DayofWeek',\n",
       "       'LargeBags_combined_lag_4', 'LargeBags_conventional_lag_4',\n",
       "       'LargeBags_organic_lag_4', 'Month', 'Quarter',\n",
       "       'SmallBags_combined_lag_4', 'SmallBags_conventional_lag_4',\n",
       "       'SmallBags_organic_lag_4', 'TotalBags_combined_lag_4',\n",
       "       'TotalBags_conventional_lag_4', 'TotalBags_organic_lag_4',\n",
       "       'TotalUS_4046_combined_lag_4', 'TotalUS_4225_combined_lag_4',\n",
       "       'TotalUS_4770_combined_lag_4', 'TotalUS_AveragePrice_combined_lag_4',\n",
       "       'TotalUS_LargeBags_combined_lag_4', 'TotalUS_SmallBags_combined_lag_4',\n",
       "       'TotalUS_TotalBags_combined_lag_4',\n",
       "       'TotalUS_TotalVolume_combined_lag_4',\n",
       "       'TotalUS_XLargeBags_combined_lag_4', 'TotalVolume_combined_lag_4',\n",
       "       'TotalVolume_conventional_lag_4', 'TotalVolume_organic_lag_4',\n",
       "       'Type_conventional', 'Type_organic', 'WeekofYear',\n",
       "       'XLargeBags_combined_lag_4', 'XLargeBags_conventional_lag_4',\n",
       "       'XLargeBags_organic_lag_4', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.79\n",
       "1      1.22\n",
       "2      1.77\n",
       "3      1.24\n",
       "4      1.17\n",
       "       ... \n",
       "333    1.68\n",
       "334    1.66\n",
       "335    1.35\n",
       "336    1.57\n",
       "337    1.71\n",
       "Name: AveragePrice, Length: 338, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the feat eng in one function we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stage_2_data(merge_df, region, train_configs):\n",
    "    lags_df = make_target_region_lags_df(merge_df, region, train_configs)\n",
    "    region_filt_df = select_region(merge_df, region)\n",
    "    feat_df = pd.concat([\n",
    "        region_filt_df[['Date', 'Type', train_configs['target_name']]], \n",
    "        lags_df], axis=1)\n",
    "\n",
    "    feat_df = pd.concat([feat_df, make_time_features(feat_df)], axis=1)\n",
    "    feat_df = pd.get_dummies(feat_df, columns=['Type'], prefix='Type')\n",
    "\n",
    "    feat_df = feat_df.loc[~feat_df['Date'].isnull(), :]\n",
    "    dates = feat_df['Date']\n",
    "    feat_df = feat_df.drop(columns='Date')\n",
    "    \n",
    "    X = feat_df[feat_df.columns.difference([train_configs['target_name']])]\n",
    "    y = feat_df[train_configs['target_name']]\n",
    "    \n",
    "    return X, y, dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the main train loop i made a grid search with optuna to optimize the models. The scores and parameters were logged to MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify which regions to iterate I'll add a key \"target_regions\" to the configs like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = {\n",
    "#         \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "#         \"lags\":[4, 8, 13, 26, 52],\n",
    "#         'target_regions': merge_df['Region'].unique(),\n",
    "#         \"aux_regions\": ['TotalUS', 'West', 'Midsouth', 'Northeast', 'Southeast', 'SouthCentral'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "#         \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "#                          '4046_combined', '4225_combined', '4770_combined', \n",
    "#                          'TotalBags_combined', 'SmallBags_combined', \n",
    "#                          'LargeBags_combined', 'XLargeBags_combined'],\n",
    "#         \"aux_lags\": [4, 8, 13, 26, 52],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the code executed to get the best parameters for each region, but since it would take too long to run it here, ill be skipping it. A JSON file with my results is included in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to region_best_params.json\n"
     ]
    }
   ],
   "source": [
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import optuna\n",
    "# import feature_eng\n",
    "# import json\n",
    "\n",
    "# # Set your MLflow experiment name\n",
    "# mlflow.set_experiment(\"Optuna Hyperparameter Optimization\")\n",
    "\n",
    "# # Define the objective function for Optuna\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "#         \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5)\n",
    "#     }\n",
    "    \n",
    "#     fold_mse = []\n",
    "#     fold_mape = []\n",
    "    \n",
    "#     for fold, (train_cv_index, val_cv_index) in enumerate(tscv.split(X_train)):\n",
    "#         X_train_cv, X_val_cv = X_train.iloc[train_cv_index], X_train.iloc[val_cv_index]\n",
    "#         y_train_cv, y_val_cv = y_train.iloc[train_cv_index], y_train.iloc[val_cv_index]\n",
    "        \n",
    "#         model = xgb.XGBRegressor(**params)\n",
    "#         model.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "#         # Make predictions and compute performance\n",
    "#         y_pred_cv = model.predict(X_val_cv)\n",
    "#         mse = mean_squared_error(y_val_cv, y_pred_cv)\n",
    "#         mape = mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
    "#         fold_mse.append(mse)\n",
    "#         fold_mape.append(mape)\n",
    "    \n",
    "#     avg_mse = np.mean(fold_mse)   \n",
    "#     avg_mape = np.mean(fold_mape)    \n",
    "    \n",
    "#     return avg_mape\n",
    "\n",
    "# for region in configs['target_regions']:\n",
    "#     print(f'Training: {region}')\n",
    "#     X, y, dates = feature_eng.make_stage_2_data(merge_df, region, configs)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "#     # Start one run per region\n",
    "#     with mlflow.start_run(run_name=f\"Region: {region}\") as region_run:\n",
    "#         mlflow.log_param(\"region\", region)\n",
    "        \n",
    "#         # Expanding window CV.\n",
    "#         tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "#         # Perform hyperparameter optimization with Optuna\n",
    "#         study = optuna.create_study(direction=\"minimize\")\n",
    "#         study.optimize(objective, n_trials=40)\n",
    "        \n",
    "#         # Log the best parameters\n",
    "#         best_params = study.best_params\n",
    "#         mlflow.log_params(best_params)\n",
    "        \n",
    "#         # Log the best cross-validation scores\n",
    "#         best_mape = study.best_value\n",
    "#         mlflow.log_metric(\"best_cv_mape\", best_mape)\n",
    "\n",
    "\n",
    "# experiment_name = \"Optuna Hyperparameter Optimization\"\n",
    "# runs = mlflow.search_runs(experiment_names=['Optuna Hyperparameter Optimization'])\n",
    "# region_params_dict = {}\n",
    "\n",
    "# # Loop over each run to get parameters\n",
    "# for index, run in runs.iterrows():\n",
    "#     region = run['params.region']\n",
    "#     params_dict = {param_name.split('params.')[1]: param_value for param_name, param_value in run.items() if param_name.startswith('params.')}\n",
    "#     params_dict.pop('region')\n",
    "#     region_params_dict[region] = params_dict\n",
    "\n",
    "# # Save to JSON file\n",
    "# json_path = \"region_best_params.json\"\n",
    "# with open(json_path, 'w') as json_file:\n",
    "#     json.dump(region_params_dict, json_file, indent=4)\n",
    "\n",
    "# print(f\"Dictionary saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main tran loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the entire train set using the best cross validated parameters for each region. After that there is another retraining, this time with the entire dataset, the retrained model is then logged and registered to an MLflow server to be later fetched for the deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a smaller set of target regions so it would not take long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "        \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "        \"lags\":[4], # The lags to be calculated for all the columns of the selected target region\n",
    "        'target_regions':['Chicago', 'Albany'], # The regions i want to forecast\n",
    "        \"aux_regions\": ['TotalUS', 'West', 'Midsouth', 'Northeast', 'Southeast', 'SouthCentral'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "        \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "                         '4046_combined', '4225_combined', '4770_combined', \n",
    "                         'TotalBags_combined', 'SmallBags_combined', \n",
    "                         'LargeBags_combined', 'XLargeBags_combined'],\n",
    "        \"aux_lags\": [4], # The lags to be calculated of the aux features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "def convert_numbers(obj):\n",
    "        for key, value in obj.items():\n",
    "            if isinstance(value, str) and value.isdigit():\n",
    "                obj[key] = int(value)\n",
    "            elif isinstance(value, str):\n",
    "                try:\n",
    "                    obj[key] = float(value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        return obj\n",
    "\n",
    "def load_best_params(region, from_json=True):\n",
    "    if from_json:\n",
    "        with open('region_best_params.json') as file:\n",
    "            best_params = json.load(file, object_hook=convert_numbers)\n",
    "        if region in best_params:\n",
    "            return best_params[region]\n",
    "        else:\n",
    "            warnings.warn(f\"No best parameters found for region: {region}, returning empty defaults\")\n",
    "            return {}\n",
    "    \n",
    "    # If not loading with a JSON, load with MLflow TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizing results easily I'll make a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_train, y_true, y_pred, target_name, dates, fold=None):\n",
    "    # Plot the fold results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(dates.loc[y_train.index], y_train, label='Train')\n",
    "    plt.plot(dates.loc[y_true.index], y_true, label='True')\n",
    "    plt.plot(dates.loc[y_true.index], y_pred, label='Predicted')\n",
    "    plt.legend()\n",
    "    if fold:\n",
    "        plt.title(f\"Train, Validation, and Predicted Values - Fold {fold}\")\n",
    "    else:\n",
    "        plt.title(f\"Train, Test, and Predicted Values\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(target_name)\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the main train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning: Chicago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martim/Traive/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/martim/Traive/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:50:12] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Successfully registered model 'Chicago_AVOCADO_FORECAST_EXAMPLE'.\n",
      "Created version '1' of model 'Chicago_AVOCADO_FORECAST_EXAMPLE'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning: Albany\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martim/Traive/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/martim/Traive/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:50:18] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "Successfully registered model 'Albany_AVOCADO_FORECAST_EXAMPLE'.\n",
      "Created version '1' of model 'Albany_AVOCADO_FORECAST_EXAMPLE'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Example Experiment\")\n",
    "\n",
    "for region in configs['target_regions']:\n",
    "    print(f'Trainning: {region}')\n",
    "    X, y, dates = make_stage_2_data(merge_df, region, configs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Start one run per region\n",
    "    with mlflow.start_run(run_name=f\"Region: {region}\") as region_run:\n",
    "        mlflow.log_param(\"region\", region)\n",
    "\n",
    "        # get best params from grid search\n",
    "        params = load_best_params(region, from_json=True)\n",
    "\n",
    "        # Evaluate final model on the hold-out test set using training data only\n",
    "        final_model_cv = xgb.XGBRegressor(**params)\n",
    "        final_model_cv.fit(X_train, y_train)\n",
    "        y_test_pred = final_model_cv.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        mlflow.log_metric(\"test_mse\", test_mse)\n",
    "        \n",
    "        plot = plot_results(y_train, y_test, y_test_pred, configs['target_name'], dates)\n",
    "        plot_path = f\"plot_test.png\"\n",
    "        plot.savefig(plot_path)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        plot.close()\n",
    "        # Delete the plot file after logging it\n",
    "        if os.path.exists(plot_path):\n",
    "            os.remove(plot_path)\n",
    "        \n",
    "        final_model = xgb.XGBRegressor(**params)\n",
    "        final_model.fit(X, y)\n",
    "\n",
    "        mlflow.xgboost.log_model(final_model, artifact_path=\"final_model\", input_example=X.iloc[:1])\n",
    "        \n",
    "        # Register the model\n",
    "        model_uri = mlflow.get_artifact_uri(\"final_model\")\n",
    "        mlflow.register_model(model_uri, name=f'{region}_AVOCADO_FORECAST_EXAMPLE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can now be analyzed inside MLFlow and deployed for serving predictions with a restAPI that loads them from the MLFlow model registry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
