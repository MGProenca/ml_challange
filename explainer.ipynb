{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll explain the steps and thought process behind all my data processing, feature engineering, model creation, validation and optimizations.\n",
    "\n",
    "All the functions i wrote here were later organized in separate modules, this notebook is an example for explaining only \n",
    "\n",
    "The API will be documented separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martim/traive/ml_challenge/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My chosen task for this challange is to make an Agricultural commodity price forecasting model and implement it.\n",
    "\n",
    "For this i chose an avocado prices and sales dataset for the US that can be found here: https://www.kaggle.com/datasets/neuromusic/avocado-prices/data\n",
    "\n",
    "The dataset has weekly entries for Organic and Conventional avocados in lots of regions across the US.\n",
    "\n",
    "My specific task will be to do a 4 week ahead forecast for the average price of an avocado, for this I'll train one separate regressor model per region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are out of the box time series forecasting models, i choose to implement a regression model such as XGB for a few reasons:\n",
    "1) In my experience if well tuned it tends to perform better.\n",
    "2) Since this is an exercise that will not be worked upon in the real world and which the objective is purely a  technical evaluation, i believe a custom solution allows me more room to express skills in machine learning engineering than models like prophet.\n",
    "3) I got some free time this week. In a more time constrained environment where a couple percentage points of precision are not essential I would probably go for the easier route..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/neuromusic/avocado-prices?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629k/629k [00:00<00:00, 1.09MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"neuromusic/avocado-prices\")\n",
    "\n",
    "    destination_folder = \"./data\"\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    # Move all files from source to destination\n",
    "    for filename in os.listdir(path):\n",
    "        source_file = os.path.join(path, filename)\n",
    "        destination_file = os.path.join(destination_folder, filename)\n",
    "        shutil.move(source_file, destination_file)\n",
    "\n",
    "    df = pd.read_csv('data/avocado.csv')\n",
    "    return df\n",
    "\n",
    "df = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0               0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1               1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2               2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3               3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4               4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "...           ...         ...           ...           ...      ...        ...   \n",
       "18244           7  2018-02-04          1.63      17074.83  2046.96    1529.20   \n",
       "18245           8  2018-01-28          1.71      13888.04  1191.70    3431.50   \n",
       "18246           9  2018-01-21          1.87      13766.76  1191.92    2452.79   \n",
       "18247          10  2018-01-14          1.93      16205.22  1527.63    2981.04   \n",
       "18248          11  2018-01-07          1.62      17489.58  2894.77    2356.13   \n",
       "\n",
       "         4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0       48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1       58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2      130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3       72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4       75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "...       ...         ...         ...         ...          ...           ...   \n",
       "18244    0.00    13498.67    13066.82      431.85          0.0       organic   \n",
       "18245    0.00     9264.84     8940.04      324.80          0.0       organic   \n",
       "18246  727.94     9394.11     9351.80       42.31          0.0       organic   \n",
       "18247  727.01    10969.54    10919.54       50.00          0.0       organic   \n",
       "18248  224.53    12014.15    11988.14       26.01          0.0       organic   \n",
       "\n",
       "       year            region  \n",
       "0      2015            Albany  \n",
       "1      2015            Albany  \n",
       "2      2015            Albany  \n",
       "3      2015            Albany  \n",
       "4      2015            Albany  \n",
       "...     ...               ...  \n",
       "18244  2018  WestTexNewMexico  \n",
       "18245  2018  WestTexNewMexico  \n",
       "18246  2018  WestTexNewMexico  \n",
       "18247  2018  WestTexNewMexico  \n",
       "18248  2018  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DF has a \"Unnamed: 0\" column with repeating indices regarding the weeks of the year for each region and each type of avocado. Since i'll be dealing with the dates later this column will be dropped. \n",
    "\n",
    "The date column needs to be a datetime, and the names are not standardized, so i'll write a preprocess function to fix all this details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date')\n",
    "    # df = df.set_index('Date')\n",
    "    df = df.drop(['Unnamed: 0', 'year'], axis=1)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    df.columns = df.columns.str[0].str.upper() + df.columns.str[1:]\n",
    "    return df\n",
    "\n",
    "df = preprocess_raw_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>27365.89</td>\n",
       "      <td>9307.34</td>\n",
       "      <td>3844.81</td>\n",
       "      <td>615.28</td>\n",
       "      <td>13598.46</td>\n",
       "      <td>13061.10</td>\n",
       "      <td>537.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9593</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.49</td>\n",
       "      <td>17723.17</td>\n",
       "      <td>1189.35</td>\n",
       "      <td>15628.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>905.55</td>\n",
       "      <td>905.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>161.68</td>\n",
       "      <td>206.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>2528.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>HarrisburgScranton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.52</td>\n",
       "      <td>54956.80</td>\n",
       "      <td>3013.04</td>\n",
       "      <td>35456.88</td>\n",
       "      <td>1561.70</td>\n",
       "      <td>14925.18</td>\n",
       "      <td>11264.80</td>\n",
       "      <td>3660.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1505.12</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1129.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>374.35</td>\n",
       "      <td>186.67</td>\n",
       "      <td>187.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.36</td>\n",
       "      <td>908202.13</td>\n",
       "      <td>142681.06</td>\n",
       "      <td>463136.28</td>\n",
       "      <td>174975.75</td>\n",
       "      <td>127409.04</td>\n",
       "      <td>103579.41</td>\n",
       "      <td>22467.04</td>\n",
       "      <td>1362.59</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9010588.32</td>\n",
       "      <td>3999735.71</td>\n",
       "      <td>966589.50</td>\n",
       "      <td>30130.82</td>\n",
       "      <td>4014132.29</td>\n",
       "      <td>3398569.92</td>\n",
       "      <td>546409.74</td>\n",
       "      <td>69152.63</td>\n",
       "      <td>conventional</td>\n",
       "      <td>SouthCentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.42</td>\n",
       "      <td>163496.70</td>\n",
       "      <td>29253.30</td>\n",
       "      <td>5080.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129163.36</td>\n",
       "      <td>109052.26</td>\n",
       "      <td>20111.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>SouthCentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17673</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.70</td>\n",
       "      <td>190257.38</td>\n",
       "      <td>29644.09</td>\n",
       "      <td>70982.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89631.19</td>\n",
       "      <td>89424.11</td>\n",
       "      <td>207.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8814</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1774776.77</td>\n",
       "      <td>63905.98</td>\n",
       "      <td>908653.71</td>\n",
       "      <td>843.45</td>\n",
       "      <td>801373.63</td>\n",
       "      <td>774634.09</td>\n",
       "      <td>23833.93</td>\n",
       "      <td>2905.61</td>\n",
       "      <td>conventional</td>\n",
       "      <td>NewYork</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  TotalVolume        4046       4225       4770  \\\n",
       "11569 2015-01-04          1.75     27365.89     9307.34    3844.81     615.28   \n",
       "9593  2015-01-04          1.49     17723.17     1189.35   15628.27       0.00   \n",
       "10009 2015-01-04          1.68      2896.72      161.68     206.96       0.00   \n",
       "1819  2015-01-04          1.52     54956.80     3013.04   35456.88    1561.70   \n",
       "9333  2015-01-04          1.64      1505.12        1.27    1129.50       0.00   \n",
       "...          ...           ...          ...         ...        ...        ...   \n",
       "8574  2018-03-25          1.36    908202.13   142681.06  463136.28  174975.75   \n",
       "9018  2018-03-25          0.70   9010588.32  3999735.71  966589.50   30130.82   \n",
       "18141 2018-03-25          1.42    163496.70    29253.30    5080.04       0.00   \n",
       "17673 2018-03-25          1.70    190257.38    29644.09   70982.10       0.00   \n",
       "8814  2018-03-25          1.34   1774776.77    63905.98  908653.71     843.45   \n",
       "\n",
       "        TotalBags   SmallBags  LargeBags  XLargeBags          Type  \\\n",
       "11569    13598.46    13061.10     537.36        0.00       organic   \n",
       "9593       905.55      905.55       0.00        0.00       organic   \n",
       "10009     2528.08     2528.08       0.00        0.00       organic   \n",
       "1819     14925.18    11264.80    3660.38        0.00  conventional   \n",
       "9333       374.35      186.67     187.68        0.00       organic   \n",
       "...           ...         ...        ...         ...           ...   \n",
       "8574    127409.04   103579.41   22467.04     1362.59  conventional   \n",
       "9018   4014132.29  3398569.92  546409.74    69152.63  conventional   \n",
       "18141   129163.36   109052.26   20111.10        0.00       organic   \n",
       "17673    89631.19    89424.11     207.08        0.00       organic   \n",
       "8814    801373.63   774634.09   23833.93     2905.61  conventional   \n",
       "\n",
       "                   Region  \n",
       "11569           Southeast  \n",
       "9593              Chicago  \n",
       "10009  HarrisburgScranton  \n",
       "1819           Pittsburgh  \n",
       "9333                Boise  \n",
       "...                   ...  \n",
       "8574              Chicago  \n",
       "9018         SouthCentral  \n",
       "18141        SouthCentral  \n",
       "17673          California  \n",
       "8814              NewYork  \n",
       "\n",
       "[18249 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since i decided that i want to forecast the average avocado prices i need to aggregate the data that currently is separated by types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives a group and combines all the variables\n",
    "def aggregate_types(group):\n",
    "    total_volume = group['TotalVolume'].sum()\n",
    "    weighted_avg = (group['AveragePrice'] * group['TotalVolume']).sum() / total_volume\n",
    "    return pd.Series({\n",
    "        'Date': group['Date'].iloc[0],\n",
    "        'Region': group['Region'].iloc[0],\n",
    "        'AveragePrice_combined': weighted_avg, # The average price is wighted against the total volumes\n",
    "        'TotalVolume_combined': total_volume,\n",
    "        '4046_combined': group['4046'].sum(),\n",
    "        '4225_combined': group['4225'].sum(),\n",
    "        '4770_combined': group['4770'].sum(),\n",
    "        'TotalBags_combined': group['TotalBags'].sum(),\n",
    "        'SmallBags_combined': group['SmallBags'].sum(),\n",
    "        'LargeBags_combined': group['LargeBags'].sum(),\n",
    "        'XLargeBags_combined': group['XLargeBags'].sum(),\n",
    "    })\n",
    "\n",
    "def group_by_region(df):\n",
    "    combined_df = df.groupby(['Date', 'Region'])[df.columns].apply(aggregate_types).reset_index(drop=True)\n",
    "    return combined_df\n",
    "\n",
    "grouped_df = group_by_region(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the differences for an example date and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1373.95</td>\n",
       "      <td>57.42</td>\n",
       "      <td>153.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.9</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  AveragePrice  TotalVolume     4046      4225  4770  \\\n",
       "9177 2015-01-04          1.79      1373.95    57.42    153.88   0.0   \n",
       "51   2015-01-04          1.22     40873.28  2819.50  28287.42  49.9   \n",
       "\n",
       "      TotalBags  SmallBags  LargeBags  XLargeBags          Type  Region  \n",
       "9177    1162.65    1162.65       0.00         0.0       organic  Albany  \n",
       "51      9716.46    9186.93     529.53         0.0  conventional  Albany  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Date'] == '2015-01-04') & (df['Region'] == 'Albany')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>AveragePrice_combined</th>\n",
       "      <th>TotalVolume_combined</th>\n",
       "      <th>4046_combined</th>\n",
       "      <th>4225_combined</th>\n",
       "      <th>4770_combined</th>\n",
       "      <th>TotalBags_combined</th>\n",
       "      <th>SmallBags_combined</th>\n",
       "      <th>LargeBags_combined</th>\n",
       "      <th>XLargeBags_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.238537</td>\n",
       "      <td>42247.23</td>\n",
       "      <td>2876.92</td>\n",
       "      <td>28441.3</td>\n",
       "      <td>49.9</td>\n",
       "      <td>10879.11</td>\n",
       "      <td>10349.58</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Region  AveragePrice_combined  TotalVolume_combined  \\\n",
       "0 2015-01-04  Albany               1.238537              42247.23   \n",
       "\n",
       "   4046_combined  4225_combined  4770_combined  TotalBags_combined  \\\n",
       "0        2876.92        28441.3           49.9            10879.11   \n",
       "\n",
       "   SmallBags_combined  LargeBags_combined  XLargeBags_combined  \n",
       "0            10349.58              529.53                  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[(grouped_df['Date'] == '2015-01-04') & (grouped_df['Region'] == 'Albany')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i run the models in this aggregated data i loose the information about the dinamic between organic and conventional sales, so lets get this info back. For this I'll pivot the data and add the values as columns to my aggregated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_and_merge_numerical_columns(df, grouped_df, target_name):\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    # numerical_columns = numerical_columns.drop('AveragePrice')\n",
    "    # Pivots arround date and region to separate each type value a column\n",
    "    pivot_df = df.pivot(index=['Date','Region'], columns='Type', values=numerical_columns).reset_index()\n",
    "    # Uses _ to join names\n",
    "    pivot_df.columns = pivot_df.columns.map(lambda col: '_'.join(map(str, col)).strip('_'))\n",
    "    # Merges data back toghether with the grouped DF\n",
    "    merge_df = pd.merge(pivot_df, df[['Date', 'Type', 'Region']], on=['Date', 'Region'], how='left')\n",
    "    merge_df = pd.merge(merge_df, grouped_df, on=['Date', 'Region'], how='left')\n",
    "    # Since i pivoted the columns, now each row has the information of the AveragePrice \n",
    "    # for both organic and conventional, AND a type flag separating the entries. But since\n",
    "    # I need a target for the forecast, another merge is done to get the price for the row's type\n",
    "    merge_df = pd.merge(merge_df, df[['Region', 'Date', 'Type', target_name]], on=['Date', 'Region', 'Type'], how='left')\n",
    "    return merge_df\n",
    "\n",
    "target_name = 'AveragePrice'\n",
    "merge_df = pivot_and_merge_numerical_columns(df, grouped_df, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Type</th>\n",
       "      <th>AveragePrice_conventional</th>\n",
       "      <th>AveragePrice_organic</th>\n",
       "      <th>AveragePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>conventional</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>conventional</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>BaltimoreWashington</td>\n",
       "      <td>organic</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date               Region          Type  AveragePrice_conventional  \\\n",
       "0 2015-01-04               Albany       organic                       1.22   \n",
       "1 2015-01-04               Albany  conventional                       1.22   \n",
       "2 2015-01-04              Atlanta  conventional                       1.00   \n",
       "3 2015-01-04              Atlanta       organic                       1.00   \n",
       "4 2015-01-04  BaltimoreWashington       organic                       1.08   \n",
       "\n",
       "   AveragePrice_organic  AveragePrice  \n",
       "0                  1.79          1.79  \n",
       "1                  1.79          1.22  \n",
       "2                  1.76          1.00  \n",
       "3                  1.76          1.76  \n",
       "4                  1.29          1.29  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df[['Date', 'Region', 'Type' ,'AveragePrice_conventional', 'AveragePrice_organic', 'AveragePrice']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now 2 entries for each date/region pair, one for organic an one for conventional, and those rows have information regarding the other. So i can use this to calculate lagged features in the future and since the grouping is done by date this does not leak future information for the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining everything in one function we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stage_1_data(configs):\n",
    "    df = load_raw_data()\n",
    "    df = preprocess_raw_data(df)\n",
    "    grouped_df = group_by_region(df)\n",
    "    merge_df = pivot_and_merge_numerical_columns(df, grouped_df, configs['target_name'])\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need to make features to feed my regression model.\n",
    "\n",
    "Since this is an exercise I'll be adding only lags and time related features. In a real world scenario more transformations can be applyied and tested to improve performance, such as seasonal decompositions, rolling statistics, cyclical features and etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a fuction to select one single region, since I'll be training a separate model for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_region(merge_df, region):\n",
    "    sel_df = merge_df[merge_df['Region'] == region].reset_index(drop=True)\n",
    "    return sel_df.drop(columns='Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create lagged columns for a single region, with an option for adding the region name to the created column (will be usefull later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags_single_column(sel_df, lags, lag_column, region_name=False):\n",
    "    '''Create lag features for a single region and lag column.\n",
    "\n",
    "    Parameters:\n",
    "    sel_df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    lags (list): A list of integers representing the lag periods to create.\n",
    "    lag_column (str): The name of the column for which to create lag features.\n",
    "    region_name (str or bool, optional): The name of the region to include in the lag feature names. \n",
    "                                         If False, the region name is not included. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the lag features.'''\n",
    "    # TODO Raise error if sel_df has multiple regions\n",
    "    lag_feats = pd.DataFrame(index=sel_df.index)\n",
    "    for lag in lags:\n",
    "        if region_name:\n",
    "            lag_feats[f'{region_name}_{lag_column}_lag_{lag}'] = sel_df.groupby('Type')[lag_column].shift(lag)\n",
    "        else:\n",
    "            lag_feats[f'{lag_column}_lag_{lag}'] = sel_df.groupby('Type')[lag_column].shift(lag)\n",
    "    return lag_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function that will serve to call the make_lags_single_column() function on desired columns, handling the logic for adding the col name as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_region_lags(region_filt_df, region_name, columns_to_lag, lags ,region_name_in_col = False):\n",
    "    lag_features = []\n",
    "    for col_name in columns_to_lag:\n",
    "        if region_name_in_col:\n",
    "            lag_features.append(make_lags_single_column(region_filt_df, lags, col_name, region_name))\n",
    "        else:\n",
    "            lag_features.append(make_lags_single_column(region_filt_df, lags, col_name))\n",
    "    return pd.concat(lag_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need a way to make the lagged features for a specific region from the merged dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we are at it, could it be that the market behaviour in region A influences the prices in region B?\n",
    "\n",
    "If we only calculate the lags from the target region, the models will loose this information. \n",
    "\n",
    "To account for this, I'll also calculate lags from a set of aggregated regions from the merged dataset and add them to my separate region models. Doing this i can feed the general market information to the models. \n",
    "\n",
    "Those \"Exogenous\" regions will be called aux_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To coordinate all those lagging and aux features operations I'll make a configs dictionary that will specify what needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "        \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "        \"lags\":[4], # The lags to be calculated for all the columns of the selected target region\n",
    "        \"aux_regions\": ['TotalUS'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "        \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "                         '4046_combined', '4225_combined', '4770_combined', \n",
    "                         'TotalBags_combined', 'SmallBags_combined', \n",
    "                         'LargeBags_combined', 'XLargeBags_combined'],\n",
    "        \"aux_lags\": [4], # The lags of the aux features to be calculated\n",
    "    }\n",
    "\n",
    "# Here lets use only the fourth lag and only one aux_region simplyfy the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the objective is to make a 4 weeks ahead forecast, the minimum lag I can use is 4. Less than that, the model would not work in the real world. \n",
    "\n",
    "Eg: if im in week 5 and using the second lag as a feature, my fourth week forecast would need information from week 7, which is in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally i can make the function that will receive the complete merged dataframe, the specified configs and return the lagged columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_region_lags_df(merge_df, target_region, train_configs):\n",
    "    # Lags for the target region\n",
    "    region_filt_df = select_region(merge_df, target_region)\n",
    "    columns_to_lag = merge_df.loc[:, merge_df.columns != train_configs['target_name']].select_dtypes(\n",
    "        include=['number']).columns\n",
    "    target_region_lags_df = make_region_lags(region_filt_df, target_region, columns_to_lag, train_configs['lags'])\n",
    "\n",
    "    # Lags for Auxiliary regions\n",
    "    aux_regions_lags = []\n",
    "    for aux_region_name in train_configs['aux_regions']:\n",
    "        if aux_region_name == target_region:\n",
    "            continue\n",
    "        \n",
    "        aux_region_filt_df = select_region(merge_df, aux_region_name).reset_index()\n",
    "        aux_regions_lags.append(\n",
    "            make_region_lags(\n",
    "                aux_region_filt_df, \n",
    "                aux_region_name, \n",
    "                train_configs['aux_features'], \n",
    "                train_configs['aux_lags'],\n",
    "                region_name_in_col=True))\n",
    "    aux_regions_lags_df = pd.concat(aux_regions_lags, axis=1)\n",
    "\n",
    "    return pd.concat([target_region_lags_df, aux_regions_lags_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i can get my lags with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Albany'\n",
    "lags_df = make_target_region_lags_df(merge_df, region, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice_conventional_lag_4</th>\n",
       "      <th>AveragePrice_organic_lag_4</th>\n",
       "      <th>TotalVolume_conventional_lag_4</th>\n",
       "      <th>TotalVolume_organic_lag_4</th>\n",
       "      <th>4046_conventional_lag_4</th>\n",
       "      <th>4046_organic_lag_4</th>\n",
       "      <th>4225_conventional_lag_4</th>\n",
       "      <th>4225_organic_lag_4</th>\n",
       "      <th>4770_conventional_lag_4</th>\n",
       "      <th>4770_organic_lag_4</th>\n",
       "      <th>...</th>\n",
       "      <th>XLargeBags_combined_lag_4</th>\n",
       "      <th>TotalUS_AveragePrice_combined_lag_4</th>\n",
       "      <th>TotalUS_TotalVolume_combined_lag_4</th>\n",
       "      <th>TotalUS_4046_combined_lag_4</th>\n",
       "      <th>TotalUS_4225_combined_lag_4</th>\n",
       "      <th>TotalUS_4770_combined_lag_4</th>\n",
       "      <th>TotalUS_TotalBags_combined_lag_4</th>\n",
       "      <th>TotalUS_SmallBags_combined_lag_4</th>\n",
       "      <th>TotalUS_LargeBags_combined_lag_4</th>\n",
       "      <th>TotalUS_XLargeBags_combined_lag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.45</td>\n",
       "      <td>1.43</td>\n",
       "      <td>121804.36</td>\n",
       "      <td>3817.93</td>\n",
       "      <td>8183.48</td>\n",
       "      <td>59.18</td>\n",
       "      <td>95548.47</td>\n",
       "      <td>289.85</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>451.11</td>\n",
       "      <td>0.987467</td>\n",
       "      <td>44484806.56</td>\n",
       "      <td>15969142.96</td>\n",
       "      <td>11812643.14</td>\n",
       "      <td>654696.38</td>\n",
       "      <td>16048064.96</td>\n",
       "      <td>11613094.64</td>\n",
       "      <td>4200629.04</td>\n",
       "      <td>234341.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.00</td>\n",
       "      <td>1.100729</td>\n",
       "      <td>38524817.46</td>\n",
       "      <td>13509266.77</td>\n",
       "      <td>11171955.89</td>\n",
       "      <td>554875.19</td>\n",
       "      <td>13288489.86</td>\n",
       "      <td>9806369.66</td>\n",
       "      <td>3254341.43</td>\n",
       "      <td>227778.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.00</td>\n",
       "      <td>1.100729</td>\n",
       "      <td>38524817.46</td>\n",
       "      <td>13509266.77</td>\n",
       "      <td>11171955.89</td>\n",
       "      <td>554875.19</td>\n",
       "      <td>13288489.86</td>\n",
       "      <td>9806369.66</td>\n",
       "      <td>3254341.43</td>\n",
       "      <td>227778.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.56</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.00</td>\n",
       "      <td>1.077948</td>\n",
       "      <td>41481381.31</td>\n",
       "      <td>13952770.84</td>\n",
       "      <td>10755838.42</td>\n",
       "      <td>725393.48</td>\n",
       "      <td>16046348.64</td>\n",
       "      <td>11431999.60</td>\n",
       "      <td>4310556.28</td>\n",
       "      <td>303792.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.56</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.00</td>\n",
       "      <td>1.077948</td>\n",
       "      <td>41481381.31</td>\n",
       "      <td>13952770.84</td>\n",
       "      <td>10755838.42</td>\n",
       "      <td>725393.48</td>\n",
       "      <td>16046348.64</td>\n",
       "      <td>11431999.60</td>\n",
       "      <td>4310556.28</td>\n",
       "      <td>303792.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AveragePrice_conventional_lag_4  AveragePrice_organic_lag_4  \\\n",
       "0                                NaN                         NaN   \n",
       "1                                NaN                         NaN   \n",
       "2                                NaN                         NaN   \n",
       "3                                NaN                         NaN   \n",
       "4                                NaN                         NaN   \n",
       "..                               ...                         ...   \n",
       "333                             1.45                        1.43   \n",
       "334                             1.43                        1.43   \n",
       "335                             1.43                        1.43   \n",
       "336                             1.28                        1.56   \n",
       "337                             1.28                        1.56   \n",
       "\n",
       "     TotalVolume_conventional_lag_4  TotalVolume_organic_lag_4  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "..                              ...                        ...   \n",
       "333                       121804.36                    3817.93   \n",
       "334                        85630.24                    7566.17   \n",
       "335                        85630.24                    7566.17   \n",
       "336                       104278.89                    5356.63   \n",
       "337                       104278.89                    5356.63   \n",
       "\n",
       "     4046_conventional_lag_4  4046_organic_lag_4  4225_conventional_lag_4  \\\n",
       "0                        NaN                 NaN                      NaN   \n",
       "1                        NaN                 NaN                      NaN   \n",
       "2                        NaN                 NaN                      NaN   \n",
       "3                        NaN                 NaN                      NaN   \n",
       "4                        NaN                 NaN                      NaN   \n",
       "..                       ...                 ...                      ...   \n",
       "333                  8183.48               59.18                 95548.47   \n",
       "334                  5499.73             4314.30                 61661.76   \n",
       "335                  5499.73             4314.30                 61661.76   \n",
       "336                 10368.77              816.56                 59723.32   \n",
       "337                 10368.77              816.56                 59723.32   \n",
       "\n",
       "     4225_organic_lag_4  4770_conventional_lag_4  4770_organic_lag_4  ...  \\\n",
       "0                   NaN                      NaN                 NaN  ...   \n",
       "1                   NaN                      NaN                 NaN  ...   \n",
       "2                   NaN                      NaN                 NaN  ...   \n",
       "3                   NaN                      NaN                 NaN  ...   \n",
       "4                   NaN                      NaN                 NaN  ...   \n",
       "..                  ...                      ...                 ...  ...   \n",
       "333              289.85                     61.0                 0.0  ...   \n",
       "334              251.85                     75.0                 0.0  ...   \n",
       "335              251.85                     75.0                 0.0  ...   \n",
       "336              532.59                     48.0                 0.0  ...   \n",
       "337              532.59                     48.0                 0.0  ...   \n",
       "\n",
       "     XLargeBags_combined_lag_4  TotalUS_AveragePrice_combined_lag_4  \\\n",
       "0                          NaN                                  NaN   \n",
       "1                          NaN                                  NaN   \n",
       "2                          NaN                                  NaN   \n",
       "3                          NaN                                  NaN   \n",
       "4                          NaN                                  NaN   \n",
       "..                         ...                                  ...   \n",
       "333                     451.11                             0.987467   \n",
       "334                     380.00                             1.100729   \n",
       "335                     380.00                             1.100729   \n",
       "336                     310.00                             1.077948   \n",
       "337                     310.00                             1.077948   \n",
       "\n",
       "     TotalUS_TotalVolume_combined_lag_4  TotalUS_4046_combined_lag_4  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "..                                  ...                          ...   \n",
       "333                         44484806.56                  15969142.96   \n",
       "334                         38524817.46                  13509266.77   \n",
       "335                         38524817.46                  13509266.77   \n",
       "336                         41481381.31                  13952770.84   \n",
       "337                         41481381.31                  13952770.84   \n",
       "\n",
       "     TotalUS_4225_combined_lag_4  TotalUS_4770_combined_lag_4  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "..                           ...                          ...   \n",
       "333                  11812643.14                    654696.38   \n",
       "334                  11171955.89                    554875.19   \n",
       "335                  11171955.89                    554875.19   \n",
       "336                  10755838.42                    725393.48   \n",
       "337                  10755838.42                    725393.48   \n",
       "\n",
       "     TotalUS_TotalBags_combined_lag_4  TotalUS_SmallBags_combined_lag_4  \\\n",
       "0                                 NaN                               NaN   \n",
       "1                                 NaN                               NaN   \n",
       "2                                 NaN                               NaN   \n",
       "3                                 NaN                               NaN   \n",
       "4                                 NaN                               NaN   \n",
       "..                                ...                               ...   \n",
       "333                       16048064.96                       11613094.64   \n",
       "334                       13288489.86                        9806369.66   \n",
       "335                       13288489.86                        9806369.66   \n",
       "336                       16046348.64                       11431999.60   \n",
       "337                       16046348.64                       11431999.60   \n",
       "\n",
       "     TotalUS_LargeBags_combined_lag_4  TotalUS_XLargeBags_combined_lag_4  \n",
       "0                                 NaN                                NaN  \n",
       "1                                 NaN                                NaN  \n",
       "2                                 NaN                                NaN  \n",
       "3                                 NaN                                NaN  \n",
       "4                                 NaN                                NaN  \n",
       "..                                ...                                ...  \n",
       "333                        4200629.04                          234341.28  \n",
       "334                        3254341.43                          227778.77  \n",
       "335                        3254341.43                          227778.77  \n",
       "336                        4310556.28                          303792.76  \n",
       "337                        4310556.28                          303792.76  \n",
       "\n",
       "[338 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice_conventional_lag_4', 'AveragePrice_organic_lag_4',\n",
       "       'TotalVolume_conventional_lag_4', 'TotalVolume_organic_lag_4',\n",
       "       '4046_conventional_lag_4', '4046_organic_lag_4',\n",
       "       '4225_conventional_lag_4', '4225_organic_lag_4',\n",
       "       '4770_conventional_lag_4', '4770_organic_lag_4',\n",
       "       'TotalBags_conventional_lag_4', 'TotalBags_organic_lag_4',\n",
       "       'SmallBags_conventional_lag_4', 'SmallBags_organic_lag_4',\n",
       "       'LargeBags_conventional_lag_4', 'LargeBags_organic_lag_4',\n",
       "       'XLargeBags_conventional_lag_4', 'XLargeBags_organic_lag_4',\n",
       "       'AveragePrice_combined_lag_4', 'TotalVolume_combined_lag_4',\n",
       "       '4046_combined_lag_4', '4225_combined_lag_4', '4770_combined_lag_4',\n",
       "       'TotalBags_combined_lag_4', 'SmallBags_combined_lag_4',\n",
       "       'LargeBags_combined_lag_4', 'XLargeBags_combined_lag_4',\n",
       "       'TotalUS_AveragePrice_combined_lag_4',\n",
       "       'TotalUS_TotalVolume_combined_lag_4', 'TotalUS_4046_combined_lag_4',\n",
       "       'TotalUS_4225_combined_lag_4', 'TotalUS_4770_combined_lag_4',\n",
       "       'TotalUS_TotalBags_combined_lag_4', 'TotalUS_SmallBags_combined_lag_4',\n",
       "       'TotalUS_LargeBags_combined_lag_4',\n",
       "       'TotalUS_XLargeBags_combined_lag_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encodes and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add back date, type and target info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_filt_df = select_region(merge_df, region)\n",
    "feat_df = pd.concat([\n",
    "    region_filt_df[['Date', 'Type', configs['target_name']]], \n",
    "    lags_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression models need those, so lets add them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_features(sel_df):\n",
    "    time_feats = pd.DataFrame(index=sel_df.index)\n",
    "    dates = sel_df['Date']\n",
    "    time_feats['Year'] = dates.dt.year\n",
    "    time_feats['Month'] = dates.dt.month\n",
    "    time_feats['Day'] = dates.dt.day\n",
    "    time_feats['DayofWeek'] = dates.dt.dayofweek\n",
    "    time_feats[\"WeekofYear\"] = dates.dt.isocalendar().week\n",
    "    time_feats[\"Quarter\"] = dates.dt.quarter\n",
    "    return time_feats\n",
    "\n",
    "feat_df = pd.concat([feat_df, make_time_features(feat_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.get_dummies(feat_df, columns=['Type'], prefix='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are concatenating, with different regions, there is a chance some dates are present in one but not the other, so just dropping the nulls solves it. (In the real world more appropriate data quality checks can be implemented in a prior data engineering stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = feat_df.loc[~feat_df['Date'].isnull(), :]\n",
    "dates = feat_df['Date'] # also store the dates not to loose the info (usefull for plotting)\n",
    "feat_df = feat_df.drop(columns='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, now I'll make the model ready data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat_df[feat_df.columns.difference([configs['target_name']])]\n",
    "y = feat_df[configs['target_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4046_combined_lag_4</th>\n",
       "      <th>4046_conventional_lag_4</th>\n",
       "      <th>4046_organic_lag_4</th>\n",
       "      <th>4225_combined_lag_4</th>\n",
       "      <th>4225_conventional_lag_4</th>\n",
       "      <th>4225_organic_lag_4</th>\n",
       "      <th>4770_combined_lag_4</th>\n",
       "      <th>4770_conventional_lag_4</th>\n",
       "      <th>4770_organic_lag_4</th>\n",
       "      <th>AveragePrice_combined_lag_4</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalVolume_combined_lag_4</th>\n",
       "      <th>TotalVolume_conventional_lag_4</th>\n",
       "      <th>TotalVolume_organic_lag_4</th>\n",
       "      <th>Type_conventional</th>\n",
       "      <th>Type_organic</th>\n",
       "      <th>WeekofYear</th>\n",
       "      <th>XLargeBags_combined_lag_4</th>\n",
       "      <th>XLargeBags_conventional_lag_4</th>\n",
       "      <th>XLargeBags_organic_lag_4</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>8242.66</td>\n",
       "      <td>8183.48</td>\n",
       "      <td>59.18</td>\n",
       "      <td>95838.32</td>\n",
       "      <td>95548.47</td>\n",
       "      <td>289.85</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.449392</td>\n",
       "      <td>...</td>\n",
       "      <td>125622.29</td>\n",
       "      <td>121804.36</td>\n",
       "      <td>3817.93</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>451.11</td>\n",
       "      <td>451.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>9814.03</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61913.61</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>93196.41</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>380.00</td>\n",
       "      <td>380.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>9814.03</td>\n",
       "      <td>5499.73</td>\n",
       "      <td>4314.30</td>\n",
       "      <td>61913.61</td>\n",
       "      <td>61661.76</td>\n",
       "      <td>251.85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>93196.41</td>\n",
       "      <td>85630.24</td>\n",
       "      <td>7566.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>380.00</td>\n",
       "      <td>380.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>11185.33</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>60255.91</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293680</td>\n",
       "      <td>...</td>\n",
       "      <td>109635.52</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>310.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>11185.33</td>\n",
       "      <td>10368.77</td>\n",
       "      <td>816.56</td>\n",
       "      <td>60255.91</td>\n",
       "      <td>59723.32</td>\n",
       "      <td>532.59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293680</td>\n",
       "      <td>...</td>\n",
       "      <td>109635.52</td>\n",
       "      <td>104278.89</td>\n",
       "      <td>5356.63</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>310.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4046_combined_lag_4  4046_conventional_lag_4  4046_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333              8242.66                  8183.48               59.18   \n",
       "334              9814.03                  5499.73             4314.30   \n",
       "335              9814.03                  5499.73             4314.30   \n",
       "336             11185.33                 10368.77              816.56   \n",
       "337             11185.33                 10368.77              816.56   \n",
       "\n",
       "     4225_combined_lag_4  4225_conventional_lag_4  4225_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333             95838.32                 95548.47              289.85   \n",
       "334             61913.61                 61661.76              251.85   \n",
       "335             61913.61                 61661.76              251.85   \n",
       "336             60255.91                 59723.32              532.59   \n",
       "337             60255.91                 59723.32              532.59   \n",
       "\n",
       "     4770_combined_lag_4  4770_conventional_lag_4  4770_organic_lag_4  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "3                    NaN                      NaN                 NaN   \n",
       "4                    NaN                      NaN                 NaN   \n",
       "..                   ...                      ...                 ...   \n",
       "333                 61.0                     61.0                 0.0   \n",
       "334                 75.0                     75.0                 0.0   \n",
       "335                 75.0                     75.0                 0.0   \n",
       "336                 48.0                     48.0                 0.0   \n",
       "337                 48.0                     48.0                 0.0   \n",
       "\n",
       "     AveragePrice_combined_lag_4  ...  TotalVolume_combined_lag_4  \\\n",
       "0                            NaN  ...                         NaN   \n",
       "1                            NaN  ...                         NaN   \n",
       "2                            NaN  ...                         NaN   \n",
       "3                            NaN  ...                         NaN   \n",
       "4                            NaN  ...                         NaN   \n",
       "..                           ...  ...                         ...   \n",
       "333                     1.449392  ...                   125622.29   \n",
       "334                     1.430000  ...                    93196.41   \n",
       "335                     1.430000  ...                    93196.41   \n",
       "336                     1.293680  ...                   109635.52   \n",
       "337                     1.293680  ...                   109635.52   \n",
       "\n",
       "     TotalVolume_conventional_lag_4  TotalVolume_organic_lag_4  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "..                              ...                        ...   \n",
       "333                       121804.36                    3817.93   \n",
       "334                        85630.24                    7566.17   \n",
       "335                        85630.24                    7566.17   \n",
       "336                       104278.89                    5356.63   \n",
       "337                       104278.89                    5356.63   \n",
       "\n",
       "     Type_conventional  Type_organic  WeekofYear  XLargeBags_combined_lag_4  \\\n",
       "0                False          True           1                        NaN   \n",
       "1                 True         False           1                        NaN   \n",
       "2                False          True           2                        NaN   \n",
       "3                 True         False           2                        NaN   \n",
       "4                 True         False           3                        NaN   \n",
       "..                 ...           ...         ...                        ...   \n",
       "333              False          True          10                     451.11   \n",
       "334              False          True          11                     380.00   \n",
       "335               True         False          11                     380.00   \n",
       "336               True         False          12                     310.00   \n",
       "337              False          True          12                     310.00   \n",
       "\n",
       "     XLargeBags_conventional_lag_4  XLargeBags_organic_lag_4  Year  \n",
       "0                              NaN                       NaN  2015  \n",
       "1                              NaN                       NaN  2015  \n",
       "2                              NaN                       NaN  2015  \n",
       "3                              NaN                       NaN  2015  \n",
       "4                              NaN                       NaN  2015  \n",
       "..                             ...                       ...   ...  \n",
       "333                         451.11                       0.0  2018  \n",
       "334                         380.00                       0.0  2018  \n",
       "335                         380.00                       0.0  2018  \n",
       "336                         310.00                       0.0  2018  \n",
       "337                         310.00                       0.0  2018  \n",
       "\n",
       "[338 rows x 44 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4046_combined_lag_4', '4046_conventional_lag_4', '4046_organic_lag_4',\n",
       "       '4225_combined_lag_4', '4225_conventional_lag_4', '4225_organic_lag_4',\n",
       "       '4770_combined_lag_4', '4770_conventional_lag_4', '4770_organic_lag_4',\n",
       "       'AveragePrice_combined_lag_4', 'AveragePrice_conventional_lag_4',\n",
       "       'AveragePrice_organic_lag_4', 'Day', 'DayofWeek',\n",
       "       'LargeBags_combined_lag_4', 'LargeBags_conventional_lag_4',\n",
       "       'LargeBags_organic_lag_4', 'Month', 'Quarter',\n",
       "       'SmallBags_combined_lag_4', 'SmallBags_conventional_lag_4',\n",
       "       'SmallBags_organic_lag_4', 'TotalBags_combined_lag_4',\n",
       "       'TotalBags_conventional_lag_4', 'TotalBags_organic_lag_4',\n",
       "       'TotalUS_4046_combined_lag_4', 'TotalUS_4225_combined_lag_4',\n",
       "       'TotalUS_4770_combined_lag_4', 'TotalUS_AveragePrice_combined_lag_4',\n",
       "       'TotalUS_LargeBags_combined_lag_4', 'TotalUS_SmallBags_combined_lag_4',\n",
       "       'TotalUS_TotalBags_combined_lag_4',\n",
       "       'TotalUS_TotalVolume_combined_lag_4',\n",
       "       'TotalUS_XLargeBags_combined_lag_4', 'TotalVolume_combined_lag_4',\n",
       "       'TotalVolume_conventional_lag_4', 'TotalVolume_organic_lag_4',\n",
       "       'Type_conventional', 'Type_organic', 'WeekofYear',\n",
       "       'XLargeBags_combined_lag_4', 'XLargeBags_conventional_lag_4',\n",
       "       'XLargeBags_organic_lag_4', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.79\n",
       "1      1.22\n",
       "2      1.77\n",
       "3      1.24\n",
       "4      1.17\n",
       "       ... \n",
       "333    1.68\n",
       "334    1.66\n",
       "335    1.35\n",
       "336    1.57\n",
       "337    1.71\n",
       "Name: AveragePrice, Length: 338, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the feat eng in one function we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stage_2_data(merge_df, region, train_configs):\n",
    "    lags_df = make_target_region_lags_df(merge_df, region, train_configs)\n",
    "    region_filt_df = select_region(merge_df, region)\n",
    "    feat_df = pd.concat([\n",
    "        region_filt_df[['Date', 'Type', train_configs['target_name']]], \n",
    "        lags_df], axis=1)\n",
    "\n",
    "    feat_df = pd.concat([feat_df, make_time_features(feat_df)], axis=1)\n",
    "    feat_df = pd.get_dummies(feat_df, columns=['Type'], prefix='Type')\n",
    "\n",
    "    feat_df = feat_df.loc[~feat_df['Date'].isnull(), :]\n",
    "    dates = feat_df['Date']\n",
    "    feat_df = feat_df.drop(columns='Date')\n",
    "    \n",
    "    X = feat_df[feat_df.columns.difference([train_configs['target_name']])]\n",
    "    y = feat_df[train_configs['target_name']]\n",
    "    \n",
    "    return X, y, dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the main train loop i made a grid search with optuna to optimize the models. The scores and parameters were logged to MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify which regions to iterate I'll add a key \"target_regions\" to the configs like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = {\n",
    "#         \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "#         \"lags\":[4, 8, 13, 26, 52],\n",
    "#         'target_regions': merge_df['Region'].unique(),\n",
    "#         \"aux_regions\": ['TotalUS', 'West', 'Midsouth', 'Northeast', 'Southeast', 'SouthCentral'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "#         \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "#                          '4046_combined', '4225_combined', '4770_combined', \n",
    "#                          'TotalBags_combined', 'SmallBags_combined', \n",
    "#                          'LargeBags_combined', 'XLargeBags_combined'],\n",
    "#         \"aux_lags\": [4, 8, 13, 26, 52],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the code executed to get the best parameters for each region, but since it would take too long to run it here, ill be skipping it. A JSON file with my results is included in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import optuna\n",
    "# import feature_eng\n",
    "# import json\n",
    "\n",
    "# # Set your MLflow experiment name\n",
    "# mlflow.set_experiment(\"Optuna Hyperparameter Optimization\")\n",
    "\n",
    "# # Define the objective function for Optuna\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "#         \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5)\n",
    "#     }\n",
    "    \n",
    "#     fold_mse = []\n",
    "#     fold_mape = []\n",
    "    \n",
    "#     for fold, (train_cv_index, val_cv_index) in enumerate(tscv.split(X_train)):\n",
    "#         X_train_cv, X_val_cv = X_train.iloc[train_cv_index], X_train.iloc[val_cv_index]\n",
    "#         y_train_cv, y_val_cv = y_train.iloc[train_cv_index], y_train.iloc[val_cv_index]\n",
    "        \n",
    "#         model = xgb.XGBRegressor(**params)\n",
    "#         model.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "#         # Make predictions and compute performance\n",
    "#         y_pred_cv = model.predict(X_val_cv)\n",
    "#         mse = mean_squared_error(y_val_cv, y_pred_cv)\n",
    "#         mape = mean_absolute_percentage_error(y_val_cv, y_pred_cv)\n",
    "#         fold_mse.append(mse)\n",
    "#         fold_mape.append(mape)\n",
    "    \n",
    "#     avg_mse = np.mean(fold_mse)   \n",
    "#     avg_mape = np.mean(fold_mape)    \n",
    "    \n",
    "#     return avg_mape\n",
    "\n",
    "# for region in configs['target_regions']:\n",
    "#     print(f'Training: {region}')\n",
    "#     X, y, dates = feature_eng.make_stage_2_data(merge_df, region, configs)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "#     # Start one run per region\n",
    "#     with mlflow.start_run(run_name=f\"Region: {region}\") as region_run:\n",
    "#         mlflow.log_param(\"region\", region)\n",
    "        \n",
    "#         # Expanding window CV.\n",
    "#         tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "#         # Perform hyperparameter optimization with Optuna\n",
    "#         study = optuna.create_study(direction=\"minimize\")\n",
    "#         study.optimize(objective, n_trials=40)\n",
    "        \n",
    "#         # Log the best parameters\n",
    "#         best_params = study.best_params\n",
    "#         mlflow.log_params(best_params)\n",
    "        \n",
    "#         # Log the best cross-validation scores\n",
    "#         best_mape = study.best_value\n",
    "#         mlflow.log_metric(\"best_cv_mape\", best_mape)\n",
    "\n",
    "\n",
    "# experiment_name = \"Optuna Hyperparameter Optimization\"\n",
    "# runs = mlflow.search_runs(experiment_names=['Optuna Hyperparameter Optimization'])\n",
    "# region_params_dict = {}\n",
    "\n",
    "# # Loop over each run to get parameters\n",
    "# for index, run in runs.iterrows():\n",
    "#     region = run['params.region']\n",
    "#     params_dict = {param_name.split('params.')[1]: param_value for param_name, param_value in run.items() if param_name.startswith('params.')}\n",
    "#     params_dict.pop('region')\n",
    "#     region_params_dict[region] = params_dict\n",
    "\n",
    "# # Save to JSON file\n",
    "# json_path = \"region_best_params.json\"\n",
    "# with open(json_path, 'w') as json_file:\n",
    "#     json.dump(region_params_dict, json_file, indent=4)\n",
    "\n",
    "# print(f\"Dictionary saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main tran loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the entire train set using the best cross validated parameters for each region. After that there is another retraining, this time with the entire dataset, the retrained model is then logged and registered to an MLflow server to be later fetched for the deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a smaller set of target regions so it would not take long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "        \"target_name\": \"AveragePrice\", # Name of the target variable to predict\n",
    "        \"lags\":[4], # The lags to be calculated for all the columns of the selected target region\n",
    "        'target_regions':['Chicago', 'Albany'], # The regions i want to forecast\n",
    "        \"aux_regions\": ['TotalUS', 'West', 'Midsouth', 'Northeast', 'Southeast', 'SouthCentral'], # \"Exogenous\" (auxiliary) regions to be used as inputs when predicting the target region\n",
    "        \"aux_features\": ['AveragePrice_combined', 'TotalVolume_combined', # Features of the aux regions to include\n",
    "                         '4046_combined', '4225_combined', '4770_combined', \n",
    "                         'TotalBags_combined', 'SmallBags_combined', \n",
    "                         'LargeBags_combined', 'XLargeBags_combined'],\n",
    "        \"aux_lags\": [4], # The lags to be calculated of the aux features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "def convert_numbers(obj):\n",
    "        for key, value in obj.items():\n",
    "            if isinstance(value, str) and value.isdigit():\n",
    "                obj[key] = int(value)\n",
    "            elif isinstance(value, str):\n",
    "                try:\n",
    "                    obj[key] = float(value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        return obj\n",
    "\n",
    "def load_best_params(region, from_json=True):\n",
    "    if from_json:\n",
    "        with open('modelling/region_best_params.json') as file:\n",
    "            best_params = json.load(file, object_hook=convert_numbers)\n",
    "        if region in best_params:\n",
    "            return best_params[region]\n",
    "        else:\n",
    "            warnings.warn(f\"No best parameters found for region: {region}, returning empty defaults\")\n",
    "            return {}\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizing results easily I'll make a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_train, y_true, y_pred, target_name, dates, fold=None):\n",
    "    # Plot the fold results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(dates.loc[y_train.index], y_train, label='Train')\n",
    "    plt.plot(dates.loc[y_true.index], y_true, label='True')\n",
    "    plt.plot(dates.loc[y_true.index], y_pred, label='Predicted')\n",
    "    plt.legend()\n",
    "    if fold:\n",
    "        plt.title(f\"Train, Validation, and Predicted Values - Fold {fold}\")\n",
    "    else:\n",
    "        plt.title(f\"Train, Test, and Predicted Values\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(target_name)\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the main train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/util/connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:963\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    962\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    964\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno -3] Temporary failure in name resolution",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connection.py:445\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1331\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1091\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1094\u001b[39m \n\u001b[32m   1095\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1035\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connection.py:276\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    278\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x7a5fe3702630>: Failed to resolve 'mlflow' ([Errno -3] Temporary failure in name resolution)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExample Experiment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m region \u001b[38;5;129;01min\u001b[39;00m configs[\u001b[33m'\u001b[39m\u001b[33mtarget_regions\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTrainning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:157\u001b[39m, in \u001b[36mset_experiment\u001b[39m\u001b[34m(experiment_name, experiment_id)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         experiment = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment:\n\u001b[32m    159\u001b[39m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:1324\u001b[39m, in \u001b[36mMlflowClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Optional[Experiment]:\n\u001b[32m   1293\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[32m   1294\u001b[39m \n\u001b[32m   1295\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m \u001b[33;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[32m   1323\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:586\u001b[39m, in \u001b[36mTrackingServiceClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    579\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    580\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[33;03m        name: The experiment name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    584\u001b[39m \u001b[33;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:641\u001b[39m, in \u001b[36mRestStore.get_experiment_by_name\u001b[39m\u001b[34m(self, experiment_name)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    640\u001b[39m     req_body = message_to_json(GetExperimentByName(experiment_name=experiment_name))\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetExperimentByName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Experiment.from_proto(response_proto.experiment)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:90\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint)\u001b[39m\n\u001b[32m     88\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m     89\u001b[39m response_proto = api.Response()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:387\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    386\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     response = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    389\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:181\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = fetch_auth(host_creds.auth)\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    197\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with timeout exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m To increase the timeout, set the environment variable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m to a larger value.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mto\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/mlflow/utils/request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    234\u001b[39m env_value = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mMLFLOW_ALLOW_HTTP_REDIRECTS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m).lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:844\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m    841\u001b[39m retries = retries.increment(\n\u001b[32m    842\u001b[39m     method, url, error=new_e, _pool=\u001b[38;5;28mself\u001b[39m, _stacktrace=sys.exc_info()[\u001b[32m2\u001b[39m]\n\u001b[32m    843\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n\u001b[32m    847\u001b[39m err = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:363\u001b[39m, in \u001b[36mRetry.sleep\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m slept:\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/traive/ml_challenge/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:347\u001b[39m, in \u001b[36mRetry._sleep_backoff\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backoff <= \u001b[32m0\u001b[39m:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Example Experiment\")\n",
    "\n",
    "for region in configs['target_regions']:\n",
    "    print(f'Trainning: {region}')\n",
    "    X, y, dates = make_stage_2_data(merge_df, region, configs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Start one run per region\n",
    "    with mlflow.start_run(run_name=f\"Region: {region}\") as region_run:\n",
    "        mlflow.log_param(\"region\", region)\n",
    "\n",
    "        # get best params from grid search\n",
    "        params = load_best_params(region, from_json=True)\n",
    "\n",
    "        # Evaluate final model on the hold-out test set using training data only\n",
    "        final_model_cv = xgb.XGBRegressor(**params)\n",
    "        final_model_cv.fit(X_train, y_train)\n",
    "        y_test_pred = final_model_cv.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        mlflow.log_metric(\"test_mse\", test_mse)\n",
    "        \n",
    "        plot = plot_results(y_train, y_test, y_test_pred, configs['target_name'], dates)\n",
    "        plot_path = f\"plot_test.png\"\n",
    "        plot.savefig(plot_path)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        plot.close()\n",
    "        # Delete the plot file after logging it\n",
    "        if os.path.exists(plot_path):\n",
    "            os.remove(plot_path)\n",
    "        \n",
    "        final_model = xgb.XGBRegressor(**params)\n",
    "        final_model.fit(X, y)\n",
    "\n",
    "        mlflow.xgboost.log_model(final_model, artifact_path=\"final_model\", input_example=X.iloc[:1])\n",
    "        \n",
    "        # Register the model\n",
    "        model_uri = mlflow.get_artifact_uri(\"final_model\")\n",
    "        mlflow.register_model(model_uri, name=f'{region}_AVOCADO_FORECAST_EXAMPLE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models can now be analyzed inside MLFlow and deployed for serving predictions with a restAPI that loads them from the MLFlow model registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/predict/Albany\"\n",
    "\n",
    "# Prepare the payload based on the required inputs\n",
    "payload_df = X.copy()\n",
    "# payload_df['4046_combined_lag_13'] = 'banana'\n",
    "payload_df = payload_df.iloc[[-25, -1]]\n",
    "payload = payload_df.to_dict(orient='records')\n",
    "\n",
    "# Make a prediction request to the API\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "# Print the results\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response JSON:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this\n",
    "\n",
    "# TODO API documentation\n",
    "\n",
    "# TODO move EDA here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
